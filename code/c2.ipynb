{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('py38_cv': conda)",
   "metadata": {
    "interpreter": {
     "hash": "ba15a1d979e8ac337d80e71852c3e63572e72a2fa439e8c45e7ad782aa6c2900"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Key words\n",
    "- cifar10\n",
    "- vgg16 (freezing params)\n",
    "- transfer learning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### packages and globe settings"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, transforms, utils, models\n",
    "from torch.utils import data\n",
    "from torchkeras import summary, Model\n",
    "from sklearn.metrics import precision_score, accuracy_score\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "\n",
    "CIFAR_ROOT = os.path.join('..', 'data')\n",
    "CIFAR10_PATH = os.path.join(CIFAR_ROOT, 'cifar-10-batches-py')\n",
    "\n",
    "HISTORY_FILE = os.path.join(CIFAR10_PATH, 'c2_cifar10_history.csv')\n",
    "WEIGHT_FILE = os.path.join(CIFAR10_PATH, 'c2_cifar10_weight.pth')\n",
    "\n",
    "HISTORY1_FILE = os.path.join(CIFAR10_PATH, 'c2_cifar10_history1.csv')\n",
    "HISTORY2_FILE = os.path.join(CIFAR10_PATH, 'c2_cifar10_history2.csv')\n",
    "\n",
    "WEIGHT1_FILE = os.path.join(CIFAR10_PATH, 'c2_cifar10_weight1.pth')\n",
    "WEIGHT2_FILE = os.path.join(CIFAR10_PATH, 'c2_cifar10_weight2.pth')\n",
    "\n",
    "NB_CLASSES = 10\n",
    "NROWS = 8\n",
    "\n",
    "IMAGE_MEAN = 0.5\n",
    "IMAGE_STD = 0.5\n",
    "IMAGE_SIZE = 32\n",
    "IMAGE_CHANNEL = 3\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "VAL_BATCH_SIZE = 64\n",
    "LR = 1e-3"
   ]
  },
  {
   "source": [
    "### common codes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "def plot_metric(dfhistory, metric):\n",
    "    train_metrics = dfhistory[metric]\n",
    "    val_metrics = dfhistory['val_'+metric]\n",
    "    epochs = range(1, len(train_metrics) + 1)\n",
    "    plt.plot(epochs, train_metrics, 'bo--')\n",
    "    plt.plot(epochs, val_metrics, 'ro-')\n",
    "    plt.title('Training and validation '+ metric)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([\"train_\"+metric, 'valid_'+metric])\n",
    "    plt.show()\n",
    "\n",
    "def plot_images(features, mean=0.5, std=0.5, nrows=8, figsize=(2, 2)):\n",
    "    # images: tensor (B, C, H, W), grid_image: ndarray (C, H, W)\n",
    "    grid_image = utils.make_grid(features, nrow=nrows).numpy()\n",
    "    grid_image = mean + grid_image * std\n",
    "\n",
    "    # imshow (H, W, C)\n",
    "    grid_image = grid_image.transpose(1, 2, 0)\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(grid_image)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()\n",
    "\n",
    "# save and load\n",
    "def save_history(model, file, mode='csv'):\n",
    "    assert mode == 'csv'\n",
    "    assert type(model.history) is pd.DataFrame\n",
    "    model.history.to_csv(file)\n",
    "\n",
    "def save_weight(model, file):\n",
    "    weights = dict()\n",
    "    weights.update({'epoch': model.epoch})\n",
    "    weights.update({'net': model.state_dict()})\n",
    "    weights.update({'optimizer': model.optim.state_dict()})\n",
    "    torch.save(weights, file)\n",
    "\n",
    "def load_history(file, index_col='epoch', mode='csv'):\n",
    "    assert mode == 'csv'\n",
    "    return pd.read_csv(file, index_col=index_col)\n",
    "\n",
    "def load_weight(model, file, net_only=False):\n",
    "    weights = torch.load(file)\n",
    "    model.load_state_dict(weights['net'])\n",
    "    if not net_only:\n",
    "        model.epoch = weights.get('epoch', 0)\n",
    "        model.optim.load_state_dict(weights['optimizer'])\n",
    "    return model\n",
    "\n",
    "# metrics\n",
    "def precision_metrics(targets, labels):\n",
    "    # targets (-1, C), labels (-1)\n",
    "    y_pred = targets.data.max(1)[1].numpy()\n",
    "    y_true = labels.numpy()\n",
    "    score = precision_score(y_true, y_pred, average='macro')\n",
    "    # return (1)\n",
    "    return torch.tensor(score)\n",
    "\n",
    "def accuracy_metrics(targets, labels):\n",
    "    # targets (-1, C), labels (-1)\n",
    "    y_pred = targets.data.max(1)[1].numpy()\n",
    "    y_true = labels.numpy()\n",
    "    score = accuracy_score(y_true, y_pred)\n",
    "    # return (1)\n",
    "    return torch.tensor(score)\n",
    "\n",
    "# training functions\n",
    "def run_step(model, features, labels, train_mode=True):\n",
    "    targets = model(features)\n",
    "    \n",
    "    metrics = dict()\n",
    "    loss = model.loss_fn(targets, labels)\n",
    "    metrics.update({'%sloss' % ('' if train_mode else 'val_'): loss.item()})\n",
    "    \n",
    "    for metric_name, metric_fn in model.metrics_dict.items():\n",
    "        metric_value = metric_fn(targets, labels)\n",
    "        metrics.update({'%s%s' % ('' if train_mode else 'val_', metric_name): metric_value.item()})\n",
    "\n",
    "    loss.backward()\n",
    "    model.optim.step()\n",
    "    model.optim.zero_grad()\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def run_epoch(model, dataloader, train_mode=True, log_per_steps=200):\n",
    "    metrics_epoch = dict()\n",
    "\n",
    "    model.train(train_mode)\n",
    "    for step, (features, labels) in enumerate(dataloader, 1):\n",
    "        metrics = run_step(model, features, labels, train_mode)\n",
    "\n",
    "        # # update loss_epoch (mean)\n",
    "        # loss_epoch = (step - 1) / step * loss_epoch + metric_val / step\n",
    "        # update metric_epoch (mean)\n",
    "        for metric_name, metric_val in metrics.items():\n",
    "            if metrics_epoch.get(metric_name) == None:\n",
    "                metrics_epoch[metric_name] = metric_val\n",
    "            else:\n",
    "                metrics_epoch[metric_name] = \\\n",
    "                    (step - 1) / step * metrics_epoch[metric_name] + metric_val / step\n",
    "\n",
    "        if step % log_per_steps == 0:\n",
    "            print(\" - Step %d, %s\" % (step, metrics_epoch))\n",
    "\n",
    "    return metrics_epoch\n",
    "\n",
    "def train_model(model, dataloader_train, dataloader_valid, epochs, log_per_epochs=10, log_per_steps=200):\n",
    "    print(\"==========\" * 6)\n",
    "    print(\"= Training model\")\n",
    "    \n",
    "    metrics_list = []\n",
    "    start_epoch = 1 + model.epoch\n",
    "    end_epoch = epochs + 1 + model.epoch\n",
    "    for epoch in range(start_epoch, end_epoch):\n",
    "        metrics = dict()\n",
    "        print(\"==========\" * 6)\n",
    "        print(\"= Epoch %d/%d @ %s\" % (epoch, end_epoch - 1, datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')))\n",
    "        metrics_train = run_epoch(model, dataloader_train, train_mode=True, log_per_steps=log_per_steps)\n",
    "        metrics_valid = run_epoch(model, dataloader_valid, train_mode=False, log_per_steps=log_per_steps)\n",
    "        metrics.update({'epoch': epoch})\n",
    "        metrics.update(metrics_train)\n",
    "        metrics.update(metrics_valid)\n",
    "        metrics_list.append(metrics)\n",
    "\n",
    "        model.epoch = epoch\n",
    "\n",
    "        if epoch % log_per_epochs == 0:\n",
    "            print('= %s' % metrics)\n",
    "        \n",
    "    print(\"==========\" * 6)\n",
    "    \n",
    "    model.history = pd.DataFrame(metrics_list)\n",
    "    model.history.set_index('epoch', inplace=True)\n",
    "    return model.history\n",
    "\n",
    "def predict_model(model, features):\n",
    "    model.eval()\n",
    "    targets = model(features)\n",
    "    \n",
    "    return targets.data.max(1)[1]\n",
    "\n",
    "def eval_model(model, features, labels):\n",
    "    model.eval()\n",
    "    targets = model(features)\n",
    "\n",
    "    metrics = dict()\n",
    "    for metric_name, metric_fn in model.metrics_dict.items():\n",
    "        metric_value = metric_fn(targets, labels)\n",
    "        metrics.update({metric_name: metric_value.item()})\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "source": [
    "### datasets and dataloader"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# datasets and dataloader\n",
    "data_tf = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomGrayscale(),\n",
    "    transforms.ToTensor(),  # 0~255 -> 0~1\n",
    "    transforms.Normalize(IMAGE_MEAN, IMAGE_STD) # 0~1 -> -1~1\n",
    "])\n",
    "\n",
    "ds_train = datasets.CIFAR10(CIFAR_ROOT, train=True, transform=data_tf, download=True)\n",
    "ds_valid = datasets.CIFAR10(CIFAR_ROOT, train=False, transform=data_tf, download=True)\n",
    "\n",
    "dl_train = data.DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "dl_valid = data.DataLoader(ds_valid, batch_size=VAL_BATCH_SIZE, shuffle=True)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "source": [
    "### batch sample plot (optional)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch sample plot\n",
    "batch_features, _ = next(iter(dl_train))\n",
    "\n",
    "plot_images(batch_features, mean=IMAGE_MEAN, std=IMAGE_STD, nrows=NROWS, figsize=(8, 8))"
   ]
  },
  {
   "source": [
    "### network class for transfer learning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleVGG16(nn.Module):\n",
    "    def __init__(self, classes=10, *args, **kwargs):\n",
    "        super(SimpleVGG16, self).__init__(*args, **kwargs)\n",
    "        self.epoch = 0\n",
    "        \n",
    "        self.vgg16 = models.vgg16(pretrained=True)\n",
    "        self._freeze_vgg16()\n",
    "        \n",
    "        self.fc1 = nn.Linear(1000, classes)\n",
    "        self.logsoftmax1 = nn.LogSoftmax(1)\n",
    "\n",
    "    def _freeze_vgg16(self):\n",
    "        for param in self.vgg16.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, input):\n",
    "        input = self.vgg16(input)\n",
    "        input = self.fc1(input)\n",
    "        input = self.logsoftmax1(input)\n",
    "        return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1           [-1, 64, 32, 32]           1,792\n              ReLU-2           [-1, 64, 32, 32]               0\n            Conv2d-3           [-1, 64, 32, 32]          36,928\n              ReLU-4           [-1, 64, 32, 32]               0\n         MaxPool2d-5           [-1, 64, 16, 16]               0\n            Conv2d-6          [-1, 128, 16, 16]          73,856\n              ReLU-7          [-1, 128, 16, 16]               0\n            Conv2d-8          [-1, 128, 16, 16]         147,584\n              ReLU-9          [-1, 128, 16, 16]               0\n        MaxPool2d-10            [-1, 128, 8, 8]               0\n           Conv2d-11            [-1, 256, 8, 8]         295,168\n             ReLU-12            [-1, 256, 8, 8]               0\n           Conv2d-13            [-1, 256, 8, 8]         590,080\n             ReLU-14            [-1, 256, 8, 8]               0\n           Conv2d-15            [-1, 256, 8, 8]         590,080\n             ReLU-16            [-1, 256, 8, 8]               0\n        MaxPool2d-17            [-1, 256, 4, 4]               0\n           Conv2d-18            [-1, 512, 4, 4]       1,180,160\n             ReLU-19            [-1, 512, 4, 4]               0\n           Conv2d-20            [-1, 512, 4, 4]       2,359,808\n             ReLU-21            [-1, 512, 4, 4]               0\n           Conv2d-22            [-1, 512, 4, 4]       2,359,808\n             ReLU-23            [-1, 512, 4, 4]               0\n        MaxPool2d-24            [-1, 512, 2, 2]               0\n           Conv2d-25            [-1, 512, 2, 2]       2,359,808\n             ReLU-26            [-1, 512, 2, 2]               0\n           Conv2d-27            [-1, 512, 2, 2]       2,359,808\n             ReLU-28            [-1, 512, 2, 2]               0\n           Conv2d-29            [-1, 512, 2, 2]       2,359,808\n             ReLU-30            [-1, 512, 2, 2]               0\n        MaxPool2d-31            [-1, 512, 1, 1]               0\nAdaptiveAvgPool2d-32            [-1, 512, 7, 7]               0\n           Linear-33                 [-1, 4096]     102,764,544\n             ReLU-34                 [-1, 4096]               0\n          Dropout-35                 [-1, 4096]               0\n           Linear-36                 [-1, 4096]      16,781,312\n             ReLU-37                 [-1, 4096]               0\n          Dropout-38                 [-1, 4096]               0\n           Linear-39                 [-1, 1000]       4,097,000\n           Linear-40                   [-1, 10]          10,010\n       LogSoftmax-41                   [-1, 10]               0\n================================================================\nTotal params: 138,367,554\nTrainable params: 10,010\nNon-trainable params: 138,357,544\n----------------------------------------------------------------\nInput size (MB): 0.011719\nForward/backward pass size (MB): 4.843719\nParams size (MB): 527.830330\nEstimated Total Size (MB): 532.685768\n----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "Model(SimpleVGG16()).summary(input_shape=(3, 32, 32))"
   ]
  },
  {
   "source": [
    "### model training and save history and weights"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " 400, {'loss': 1.691487196683885, 'precision': 0.47192662746204433, 'accuracy': 0.48578125000000033}\n",
      " - Step 600, {'loss': 1.705613253613314, 'precision': 0.47075569255847016, 'accuracy': 0.4846354166666669}\n",
      " - Step 800, {'loss': 1.7007703655213136, 'precision': 0.4707210082355916, 'accuracy': 0.4834765625000002}\n",
      " - Step 1000, {'loss': 1.6998088481426243, 'precision': 0.4717187454212451, 'accuracy': 0.4834687500000003}\n",
      " - Step 1200, {'loss': 1.6915812368690968, 'precision': 0.4744865594025311, 'accuracy': 0.48666666666666614}\n",
      " - Step 1400, {'loss': 1.681876653858596, 'precision': 0.47497808014296045, 'accuracy': 0.4872991071428568}\n",
      "= {'epoch': 2, 'loss': 1.6812028925310543, 'precision': 0.4741547042485401, 'accuracy': 0.4867842290467045, 'val_loss': 1.2703908362965677, 'val_precision': 0.5625284020338351, 'val_accuracy': 0.560509554140127}\n",
      "============================================================\n",
      "= Epoch 3/20 @ 2020-12-18 14:18:57\n",
      " - Step 200, {'loss': 1.6622813928127291, 'precision': 0.4742185966810964, 'accuracy': 0.4962499999999999}\n",
      " - Step 400, {'loss': 1.6607563009858148, 'precision': 0.4803893518518519, 'accuracy': 0.4960156250000007}\n",
      " - Step 600, {'loss': 1.6570399169127155, 'precision': 0.48562409010742347, 'accuracy': 0.49791666666666706}\n",
      " - Step 800, {'loss': 1.665528197437524, 'precision': 0.48335883880779723, 'accuracy': 0.49703125000000076}\n",
      " - Step 1000, {'loss': 1.6615539944767934, 'precision': 0.48329279635487976, 'accuracy': 0.4968750000000005}\n",
      " - Step 1200, {'loss': 1.6621228774885297, 'precision': 0.4832127567134509, 'accuracy': 0.49614583333333334}\n",
      " - Step 1400, {'loss': 1.6742924875872431, 'precision': 0.48146726106785576, 'accuracy': 0.4942857142857139}\n",
      "= {'epoch': 3, 'loss': 1.6744137755282265, 'precision': 0.47865667153948127, 'accuracy': 0.4925023992322447, 'val_loss': 1.2627651152337434, 'val_precision': 0.5719612433484671, 'val_accuracy': 0.5624999999999998}\n",
      "============================================================\n",
      "= Epoch 4/20 @ 2020-12-18 14:43:54\n",
      " - Step 200, {'loss': 1.6536274528503416, 'precision': 0.48207602505519154, 'accuracy': 0.4984375}\n",
      " - Step 400, {'loss': 1.6714058898389337, 'precision': 0.4773849852308189, 'accuracy': 0.4943750000000001}\n",
      " - Step 600, {'loss': 1.6805122569203368, 'precision': 0.4772112653807103, 'accuracy': 0.49312499999999987}\n",
      " - Step 800, {'loss': 1.6806676778942342, 'precision': 0.4780729263984475, 'accuracy': 0.4926171875000006}\n",
      " - Step 1000, {'loss': 1.6758253963589667, 'precision': 0.4804146446300613, 'accuracy': 0.49403125000000037}\n",
      " - Step 1200, {'loss': 1.6767868622144035, 'precision': 0.48059155991899016, 'accuracy': 0.4946614583333337}\n",
      " - Step 1400, {'loss': 1.673432442929059, 'precision': 0.48245324215026564, 'accuracy': 0.49571428571428555}\n",
      "= {'epoch': 4, 'loss': 1.6690194888596912, 'precision': 0.4835550334774575, 'accuracy': 0.4965810940499037, 'val_loss': 1.2717455496453933, 'val_precision': 0.5735976926886452, 'val_accuracy': 0.562101910828026}\n",
      "============================================================\n",
      "= Epoch 5/20 @ 2020-12-18 15:16:21\n",
      " - Step 200, {'loss': 1.63448490858078, 'precision': 0.4887479918229923, 'accuracy': 0.5075}\n",
      " - Step 400, {'loss': 1.6448399128019804, 'precision': 0.4829279741092243, 'accuracy': 0.5012500000000003}\n",
      " - Step 600, {'loss': 1.6392348830898578, 'precision': 0.4851832030109812, 'accuracy': 0.5007812500000007}\n",
      " - Step 800, {'loss': 1.6487240172922606, 'precision': 0.48330473531098594, 'accuracy': 0.49718750000000067}\n",
      " - Step 1000, {'loss': 1.6449360468387595, 'precision': 0.4843739521897858, 'accuracy': 0.49812500000000065}\n",
      " - Step 1200, {'loss': 1.651471873919167, 'precision': 0.4860525582956134, 'accuracy': 0.4982291666666673}\n",
      " - Step 1400, {'loss': 1.6609488984516676, 'precision': 0.4850754972100205, 'accuracy': 0.4970758928571435}\n",
      "= {'epoch': 5, 'loss': 1.6622227607670286, 'precision': 0.48423344910975474, 'accuracy': 0.496421145233526, 'val_loss': 1.2663308438981418, 'val_precision': 0.5708965996536247, 'val_accuracy': 0.5627985668789812}\n",
      "============================================================\n",
      "= Epoch 6/20 @ 2020-12-18 15:44:27\n",
      " - Step 200, {'loss': 1.6263482135534275, 'precision': 0.496985069059027, 'accuracy': 0.5084374999999999}\n",
      " - Step 400, {'loss': 1.64393194898963, 'precision': 0.48377482908680847, 'accuracy': 0.49687499999999996}\n",
      " - Step 600, {'loss': 1.642432185908158, 'precision': 0.48876653769327355, 'accuracy': 0.4994791666666665}\n",
      " - Step 800, {'loss': 1.6624421799182896, 'precision': 0.48550439611507334, 'accuracy': 0.49500000000000016}\n",
      " - Step 1000, {'loss': 1.6544508756399154, 'precision': 0.48618525831421683, 'accuracy': 0.4966562499999999}\n",
      " - Step 1200, {'loss': 1.6635876568655157, 'precision': 0.4842212887613928, 'accuracy': 0.49598958333333276}\n",
      " - Step 1400, {'loss': 1.6629894293206062, 'precision': 0.48486545083553995, 'accuracy': 0.4966741071428562}\n",
      "= {'epoch': 6, 'loss': 1.6650813406503713, 'precision': 0.4845284883388684, 'accuracy': 0.4961612284069087, 'val_loss': 1.2671613450262964, 'val_precision': 0.5713527570496478, 'val_accuracy': 0.565684713375796}\n",
      "============================================================\n",
      "= Epoch 7/20 @ 2020-12-18 16:11:54\n",
      " - Step 200, {'loss': 1.6474171566963205, 'precision': 0.48641926807760144, 'accuracy': 0.4914062500000001}\n",
      " - Step 400, {'loss': 1.647082641869783, 'precision': 0.4883260311447818, 'accuracy': 0.49546875}\n",
      " - Step 600, {'loss': 1.6465505696336418, 'precision': 0.4897426266634602, 'accuracy': 0.4995833333333332}\n",
      " - Step 800, {'loss': 1.642733264490963, 'precision': 0.4889583715667054, 'accuracy': 0.49968750000000023}\n",
      " - Step 1000, {'loss': 1.649654536306859, 'precision': 0.4883921073062749, 'accuracy': 0.4995312500000001}\n",
      " - Step 1200, {'loss': 1.6479218451182052, 'precision': 0.4872124914180475, 'accuracy': 0.49898437500000026}\n",
      " - Step 1400, {'loss': 1.6511077507478857, 'precision': 0.48702124957273846, 'accuracy': 0.49841517857142864}\n",
      "= {'epoch': 7, 'loss': 1.6459740508998437, 'precision': 0.4874335392556233, 'accuracy': 0.49886036468330147, 'val_loss': 1.2621669108700604, 'val_precision': 0.5746628464281688, 'val_accuracy': 0.569267515923567}\n",
      "============================================================\n",
      "= Epoch 8/20 @ 2020-12-18 16:37:32\n",
      " - Step 200, {'loss': 1.665535049736499, 'precision': 0.475603593474427, 'accuracy': 0.48874999999999985}\n",
      " - Step 400, {'loss': 1.658935304582119, 'precision': 0.47658669733044706, 'accuracy': 0.4897656250000004}\n",
      " - Step 600, {'loss': 1.644746058980622, 'precision': 0.4852255885575319, 'accuracy': 0.49583333333333285}\n",
      " - Step 800, {'loss': 1.669498609080911, 'precision': 0.4818691032347278, 'accuracy': 0.4933203125000002}\n",
      " - Step 1000, {'loss': 1.6750069634914384, 'precision': 0.4809317501325827, 'accuracy': 0.4924062499999999}\n",
      " - Step 1200, {'loss': 1.668792013774313, 'precision': 0.4807665448234882, 'accuracy': 0.49291666666666656}\n",
      " - Step 1400, {'loss': 1.6682130834885986, 'precision': 0.4825944253277581, 'accuracy': 0.49401785714285723}\n",
      "= {'epoch': 8, 'loss': 1.665579759037347, 'precision': 0.48372219553548096, 'accuracy': 0.4953214971209205, 'val_loss': 1.2702725757459175, 'val_precision': 0.5819186522590125, 'val_accuracy': 0.5738455414012739}\n",
      "============================================================\n",
      "= Epoch 9/20 @ 2020-12-18 17:06:03\n",
      " - Step 200, {'loss': 1.6233479708433158, 'precision': 0.4909703440078444, 'accuracy': 0.5007812499999995}\n",
      " - Step 400, {'loss': 1.6315653270483028, 'precision': 0.4909454614058781, 'accuracy': 0.5003906250000002}\n",
      " - Step 600, {'loss': 1.6403801997502658, 'precision': 0.4858080773650219, 'accuracy': 0.49802083333333386}\n",
      " - Step 800, {'loss': 1.628548196405176, 'precision': 0.49144757287465646, 'accuracy': 0.502421875}\n",
      " - Step 1000, {'loss': 1.6347564210295709, 'precision': 0.49035156479323194, 'accuracy': 0.5018750000000001}\n",
      " - Step 1200, {'loss': 1.6352346190313523, 'precision': 0.4892487391595029, 'accuracy': 0.5012239583333334}\n",
      " - Step 1400, {'loss': 1.637783053261894, 'precision': 0.49000451735213624, 'accuracy': 0.5017410714285713}\n",
      "= {'epoch': 9, 'loss': 1.6355051739964819, 'precision': 0.4914976472486066, 'accuracy': 0.5026991362763907, 'val_loss': 1.267128481986417, 'val_precision': 0.5792387855993144, 'val_accuracy': 0.5673765923566884}\n",
      "============================================================\n",
      "= Epoch 10/20 @ 2020-12-18 17:33:16\n",
      " - Step 200, {'loss': 1.7206877917051322, 'precision': 0.4811138097242267, 'accuracy': 0.4867187500000002}\n",
      " - Step 400, {'loss': 1.6996881838142888, 'precision': 0.4857807394380315, 'accuracy': 0.49109375000000005}\n",
      " - Step 600, {'loss': 1.6885599722464872, 'precision': 0.48715830216594147, 'accuracy': 0.49343749999999986}\n",
      " - Step 800, {'loss': 1.6850275459885586, 'precision': 0.4879139682269892, 'accuracy': 0.49453125000000037}\n",
      " - Step 1000, {'loss': 1.6810832072496409, 'precision': 0.48648658255324917, 'accuracy': 0.49450000000000033}\n",
      " - Step 1200, {'loss': 1.6697070405383894, 'precision': 0.48911092176856036, 'accuracy': 0.49744791666666666}\n",
      " - Step 1400, {'loss': 1.660099976616245, 'precision': 0.49095583646952634, 'accuracy': 0.49988839285714276}\n",
      "= {'epoch': 10, 'loss': 1.6579284180987717, 'precision': 0.49086874573811995, 'accuracy': 0.5000799744081891, 'val_loss': 1.26890872504301, 'val_precision': 0.5733461460845815, 'val_accuracy': 0.5646894904458599}\n",
      "============================================================\n",
      "= Epoch 11/20 @ 2020-12-18 17:59:59\n",
      " - Step 200, {'loss': 1.6503073993325232, 'precision': 0.48013273809523843, 'accuracy': 0.4921875000000003}\n",
      " - Step 400, {'loss': 1.6779062418639683, 'precision': 0.47816738315696666, 'accuracy': 0.49210937500000057}\n",
      " - Step 600, {'loss': 1.6666220092773445, 'precision': 0.48230565365704225, 'accuracy': 0.4968750000000003}\n",
      " - Step 800, {'loss': 1.669719523191453, 'precision': 0.48063089217880856, 'accuracy': 0.49417968750000063}\n",
      " - Step 1000, {'loss': 1.6676914921402959, 'precision': 0.48327197063738747, 'accuracy': 0.4945937500000004}\n",
      " - Step 1200, {'loss': 1.6650719942649213, 'precision': 0.48305076570805755, 'accuracy': 0.49484375000000025}\n",
      " - Step 1400, {'loss': 1.6653199974128188, 'precision': 0.48515849623260343, 'accuracy': 0.4965625000000002}\n",
      "= {'epoch': 11, 'loss': 1.661747672698166, 'precision': 0.48474131374616525, 'accuracy': 0.4971609085092771, 'val_loss': 1.273936439851286, 'val_precision': 0.574930331229926, 'val_accuracy': 0.5669785031847135}\n",
      "============================================================\n",
      "= Epoch 12/20 @ 2020-12-18 18:26:42\n",
      " - Step 200, {'loss': 1.6275042456388469, 'precision': 0.49487369127785796, 'accuracy': 0.5029687499999996}\n",
      " - Step 400, {'loss': 1.6402438746392716, 'precision': 0.4910057910453745, 'accuracy': 0.5010937499999998}\n",
      " - Step 600, {'loss': 1.645025287171204, 'precision': 0.4861856381786934, 'accuracy': 0.5005729166666665}\n",
      " - Step 800, {'loss': 1.6474644993245602, 'precision': 0.48991704699621386, 'accuracy': 0.502148437499999}\n",
      " - Step 1000, {'loss': 1.653208762109282, 'precision': 0.48874385910385915, 'accuracy': 0.4999374999999997}\n",
      " - Step 1200, {'loss': 1.6593802202244587, 'precision': 0.4865155181238512, 'accuracy': 0.4988020833333335}\n",
      " - Step 1400, {'loss': 1.655111308182987, 'precision': 0.48636047940155036, 'accuracy': 0.4995312499999999}\n",
      "= {'epoch': 12, 'loss': 1.6545813139706766, 'precision': 0.48759485488958654, 'accuracy': 0.5003998720409465, 'val_loss': 1.2490849172233778, 'val_precision': 0.5787284939364371, 'val_accuracy': 0.5756369426751594}\n",
      "============================================================\n",
      "= Epoch 13/20 @ 2020-12-18 18:52:19\n",
      " - Step 200, {'loss': 1.625736058950424, 'precision': 0.49466531986532, 'accuracy': 0.5096874999999996}\n",
      " - Step 400, {'loss': 1.6204533205926417, 'precision': 0.4945029761904764, 'accuracy': 0.5101562499999999}\n",
      " - Step 600, {'loss': 1.6309145636359845, 'precision': 0.4925674883758217, 'accuracy': 0.5051041666666676}\n",
      " - Step 800, {'loss': 1.6374429941177349, 'precision': 0.4938425304633642, 'accuracy': 0.504882812500001}\n",
      " - Step 1000, {'loss': 1.6416999102830876, 'precision': 0.49116847562930954, 'accuracy': 0.503312500000001}\n",
      " - Step 1200, {'loss': 1.645968240698175, 'precision': 0.49099772136299963, 'accuracy': 0.5030989583333337}\n",
      " - Step 1400, {'loss': 1.6439848165852633, 'precision': 0.4888875761143621, 'accuracy': 0.5025892857142861}\n",
      "= {'epoch': 13, 'loss': 1.6454915770413496, 'precision': 0.48917100886444037, 'accuracy': 0.5022192898272565, 'val_loss': 1.2621458806809351, 'val_precision': 0.5781004024426558, 'val_accuracy': 0.5710589171974526}\n",
      "============================================================\n",
      "= Epoch 14/20 @ 2020-12-18 19:17:23\n",
      " - Step 200, {'loss': 1.6526712203025806, 'precision': 0.4902729316979316, 'accuracy': 0.5009375}\n",
      " - Step 400, {'loss': 1.6671811895072453, 'precision': 0.48627656533281544, 'accuracy': 0.4989843750000003}\n",
      " - Step 600, {'loss': 1.6605727397402106, 'precision': 0.4863908904367236, 'accuracy': 0.4991666666666664}\n",
      " - Step 800, {'loss': 1.65958337508142, 'precision': 0.4863183001026758, 'accuracy': 0.49960937499999997}\n",
      " - Step 1000, {'loss': 1.6570481895208347, 'precision': 0.4864889610697948, 'accuracy': 0.5001250000000002}\n",
      " - Step 1200, {'loss': 1.663067974944907, 'precision': 0.48609598074893184, 'accuracy': 0.4998697916666668}\n",
      " - Step 1400, {'loss': 1.656917978141987, 'precision': 0.4872000602186612, 'accuracy': 0.5016071428571423}\n",
      "= {'epoch': 14, 'loss': 1.6505154455539424, 'precision': 0.48820670329587385, 'accuracy': 0.5024392194497753, 'val_loss': 1.2539958650139487, 'val_precision': 0.5733742875846665, 'val_accuracy': 0.5724522292993629}\n",
      "============================================================\n",
      "= Epoch 15/20 @ 2020-12-18 19:42:05\n",
      " - Step 200, {'loss': 1.6204076635837552, 'precision': 0.5019320142820141, 'accuracy': 0.5087499999999996}\n",
      " - Step 400, {'loss': 1.6606641867756844, 'precision': 0.4940573412698409, 'accuracy': 0.50171875}\n",
      " - Step 600, {'loss': 1.652214814225833, 'precision': 0.49743234995457175, 'accuracy': 0.5050520833333333}\n",
      " - Step 800, {'loss': 1.6489778113365203, 'precision': 0.4969421030743949, 'accuracy': 0.5058203124999991}\n",
      " - Step 1000, {'loss': 1.6436355603933333, 'precision': 0.49583578964245684, 'accuracy': 0.5058124999999999}\n",
      " - Step 1200, {'loss': 1.6405876312653223, 'precision': 0.49576757204986344, 'accuracy': 0.5056770833333326}\n",
      " - Step 1400, {'loss': 1.642972563420022, 'precision': 0.4935100834020474, 'accuracy': 0.5039955357142838}\n",
      "= {'epoch': 15, 'loss': 1.6506799146370925, 'precision': 0.49170461238839286, 'accuracy': 0.5022192898272536, 'val_loss': 1.2557647824287415, 'val_precision': 0.5773459012748077, 'val_accuracy': 0.5705613057324846}\n",
      "============================================================\n",
      "= Epoch 16/20 @ 2020-12-18 20:06:29\n",
      " - Step 200, {'loss': 1.5903830137848856, 'precision': 0.49557086940836936, 'accuracy': 0.5076562499999997}\n",
      " - Step 400, {'loss': 1.6368002480268458, 'precision': 0.4919954869204872, 'accuracy': 0.5023437500000009}\n",
      " - Step 600, {'loss': 1.6453261801600443, 'precision': 0.4918774626607962, 'accuracy': 0.5023958333333342}\n",
      " - Step 800, {'loss': 1.6501968558877682, 'precision': 0.4910431408868912, 'accuracy': 0.5025390625}\n",
      " - Step 1000, {'loss': 1.6591864023804648, 'precision': 0.4892257721291061, 'accuracy': 0.5007812499999994}\n",
      " - Step 1200, {'loss': 1.658882297029094, 'precision': 0.48789891920065603, 'accuracy': 0.49979166666666586}\n",
      " - Step 1400, {'loss': 1.6558315939988368, 'precision': 0.489882047218655, 'accuracy': 0.5003124999999996}\n",
      "= {'epoch': 16, 'loss': 1.650583639521662, 'precision': 0.49011971361379547, 'accuracy': 0.5018793985924499, 'val_loss': 1.260072031977828, 'val_precision': 0.5779966967312419, 'val_accuracy': 0.5705613057324841}\n",
      "============================================================\n",
      "= Epoch 17/20 @ 2020-12-18 20:30:50\n",
      " - Step 200, {'loss': 1.6050407209992408, 'precision': 0.49416452220618867, 'accuracy': 0.5081249999999992}\n",
      " - Step 400, {'loss': 1.6249240881204596, 'precision': 0.4948119521682019, 'accuracy': 0.5080468750000005}\n",
      " - Step 600, {'loss': 1.6613570387164724, 'precision': 0.48772854557993467, 'accuracy': 0.5014062500000004}\n",
      " - Step 800, {'loss': 1.6536339309811576, 'precision': 0.4881365714725092, 'accuracy': 0.502109375}\n",
      " - Step 1000, {'loss': 1.6545723065137832, 'precision': 0.4874126507905681, 'accuracy': 0.5001562500000003}\n",
      " - Step 1200, {'loss': 1.6571944676836312, 'precision': 0.4871810787078152, 'accuracy': 0.4996093750000004}\n",
      " - Step 1400, {'loss': 1.65255668750831, 'precision': 0.487533325476332, 'accuracy': 0.4997991071428576}\n",
      "= {'epoch': 17, 'loss': 1.6520504491953059, 'precision': 0.4875302224423841, 'accuracy': 0.500059980806142, 'val_loss': 1.2597922139866349, 'val_precision': 0.5721964778245227, 'val_accuracy': 0.570362261146497}\n",
      "============================================================\n",
      "= Epoch 18/20 @ 2020-12-18 20:55:16\n",
      " - Step 200, {'loss': 1.6317334431409838, 'precision': 0.4922045093795094, 'accuracy': 0.5059375000000002}\n",
      " - Step 400, {'loss': 1.6385476677119715, 'precision': 0.493061238375822, 'accuracy': 0.504218750000001}\n",
      " - Step 600, {'loss': 1.6465775725245453, 'precision': 0.4938586780503451, 'accuracy': 0.5036979166666672}\n",
      " - Step 800, {'loss': 1.6517785791307666, 'precision': 0.49147312960958844, 'accuracy': 0.5026171875000007}\n",
      " - Step 1000, {'loss': 1.6374110559821102, 'precision': 0.4946421408529743, 'accuracy': 0.5065000000000001}\n",
      " - Step 1200, {'loss': 1.6397077866891994, 'precision': 0.4946958206402652, 'accuracy': 0.5057552083333333}\n",
      " - Step 1400, {'loss': 1.6410081215415642, 'precision': 0.4918665751796706, 'accuracy': 0.5039062499999986}\n",
      "= {'epoch': 18, 'loss': 1.639313953165353, 'precision': 0.49305651172520387, 'accuracy': 0.5042586372360827, 'val_loss': 1.2547760214775232, 'val_precision': 0.5796312969706562, 'val_accuracy': 0.570362261146497}\n",
      "============================================================\n",
      "= Epoch 19/20 @ 2020-12-18 21:19:37\n",
      " - Step 200, {'loss': 1.6164774727821352, 'precision': 0.4932857263107262, 'accuracy': 0.5010937500000003}\n",
      " - Step 400, {'loss': 1.6777699077129364, 'precision': 0.48663545574795586, 'accuracy': 0.4990624999999999}\n",
      " - Step 600, {'loss': 1.6852551906307542, 'precision': 0.4847841705747953, 'accuracy': 0.4980208333333331}\n",
      " - Step 800, {'loss': 1.6731151816248904, 'precision': 0.4864334812660334, 'accuracy': 0.4992968749999996}\n",
      " - Step 1000, {'loss': 1.6792187998294832, 'precision': 0.48515347132034636, 'accuracy': 0.49596874999999924}\n",
      " - Step 1200, {'loss': 1.6767808626592147, 'precision': 0.48594620051373505, 'accuracy': 0.4970312499999993}\n",
      " - Step 1400, {'loss': 1.6618983719604334, 'precision': 0.4879382796931903, 'accuracy': 0.5003571428571422}\n",
      "= {'epoch': 19, 'loss': 1.6558470609320763, 'precision': 0.48927147180146124, 'accuracy': 0.5013595649392191, 'val_loss': 1.2485903843193304, 'val_precision': 0.5784249022385967, 'val_accuracy': 0.5695660828025481}\n",
      "============================================================\n",
      "= Epoch 20/20 @ 2020-12-18 21:44:17\n",
      " - Step 200, {'loss': 1.644592848420143, 'precision': 0.49321320546737235, 'accuracy': 0.5048437499999999}\n",
      " - Step 400, {'loss': 1.6612896953523164, 'precision': 0.48746869914422014, 'accuracy': 0.5001562500000002}\n",
      " - Step 600, {'loss': 1.6701493252317112, 'precision': 0.49072201816958794, 'accuracy': 0.5005729166666667}\n",
      " - Step 800, {'loss': 1.6696754951775084, 'precision': 0.491448204043257, 'accuracy': 0.5011328125000002}\n",
      " - Step 1000, {'loss': 1.6640310292243954, 'precision': 0.4903193626204057, 'accuracy': 0.5010000000000008}\n",
      " - Step 1200, {'loss': 1.6611110975593328, 'precision': 0.49121185962314545, 'accuracy': 0.5014583333333332}\n",
      " - Step 1400, {'loss': 1.6578671602479038, 'precision': 0.49220710731618567, 'accuracy': 0.5021205357142854}\n",
      "= {'epoch': 20, 'loss': 1.660450308790436, 'precision': 0.4921317604508324, 'accuracy': 0.5016194817658337, 'val_loss': 1.2490323766781277, 'val_precision': 0.5807819971923934, 'val_accuracy': 0.5745421974522298}\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# training settings (loss, optim & metrics)\n",
    "model = SimpleVGG16(NB_CLASSES)\n",
    "model.loss_fn = nn.CrossEntropyLoss()\n",
    "model.optim = optim.Adam(model.parameters(), lr=LR)\n",
    "model.metrics_dict = {\n",
    "    'precision': precision_metrics,\n",
    "    'accuracy': accuracy_metrics\n",
    "}\n",
    "\n",
    "# model training\n",
    "history = train_model(model, dl_train, dl_valid, epochs=20, log_per_epochs=1, log_per_steps=200)\n",
    "\n",
    "# save training history\n",
    "save_history(model, HISTORY1_FILE)\n",
    "\n",
    "# save weights\n",
    "save_weight(model, WEIGHT1_FILE)"
   ]
  },
  {
   "source": [
    "### re-training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleVGG16(NB_CLASSES)\n",
    "model.loss_fn = nn.CrossEntropyLoss()\n",
    "model.optim = optim.Adam(model.parameters(), lr=LR)\n",
    "model.metrics_dict = {\n",
    "    'precision': precision_metrics,\n",
    "    'accuracy': accuracy_metrics\n",
    "}\n",
    "\n",
    "# load weights\n",
    "model = load_weight(model, WEIGHT1_FILE)\n",
    "history = train_model(model, dl_train, dl_valid, 10, log_per_epochs=1, log_per_steps=200)\n",
    "\n",
    "save_history(model, HISTORY2_FILE)\n",
    "save_weight(model, WEIGHT2_FILE)\n",
    "history"
   ]
  },
  {
   "source": [
    "### metrics plot"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = load_history(HISTORY_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(history, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(history, 'precision')"
   ]
  },
  {
   "source": [
    "### prediction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, _ = next(iter(dl_valid))\n",
    "\n",
    "model = SimpleVGG16(NB_CLASSES)\n",
    "model = load_weight(model, WEIGHT_FILE, net_only=True)\n",
    "\n",
    "targets = predict_model(model, features)\n",
    "print(targets.numpy().reshape(-1, NROWS))\n",
    "\n",
    "plot_images(features, mean=IMAGE_MEAN, std=IMAGE_STD, nrows=NROWS)"
   ]
  },
  {
   "source": [
    "### evaluation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = next(iter(dl_valid))\n",
    "\n",
    "model = SimpleVGG16(NB_CLASSES)\n",
    "model.metrics_dict = {\n",
    "    'precision': precision_metrics,\n",
    "    'accuracy': accuracy_metrics\n",
    "}\n",
    "model = load_weight(model, WEIGHT_FILE, net_only=True)\n",
    "\n",
    "metrics = eval_model(model, features, labels)\n",
    "\n",
    "# print(labels.reshape(-1, NROWS))\n",
    "# plot_images(features)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-0.0046, -0.0142, -0.0822],\n",
       "        [ 0.0523, -0.0474,  0.0054],\n",
       "        [-0.0129, -0.0052, -0.0351]])"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "model = models.vgg16()\n",
    "# Model(model).summary(input_shape=(3, 32, 32))\n",
    "model.state_dict()['features.0.weight'][0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-0.5537,  0.1427,  0.5290],\n",
       "        [-0.5831,  0.3566,  0.7657],\n",
       "        [-0.6902, -0.0480,  0.4841]])"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "model1 = models.vgg16(pretrained=True)\n",
    "model1.state_dict()['features.0.weight'][0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = SimpleVGG16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = load_weight(model2, WEIGHT1_FILE, net_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-0.5784,  0.1180,  0.5037],\n",
       "        [-0.6086,  0.3356,  0.7520],\n",
       "        [-0.7151, -0.0606,  0.4800]])"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "model2.state_dict()['vgg16.features.0.weight'][0, 0, :]"
   ]
  }
 ]
}