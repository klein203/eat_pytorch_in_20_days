{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('py38_cv': conda)",
   "metadata": {
    "interpreter": {
     "hash": "ba15a1d979e8ac337d80e71852c3e63572e72a2fa439e8c45e7ad782aa6c2900"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "### packages and globe settings"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, transforms, utils, models\n",
    "from torch.utils import data\n",
    "from torchkeras import summary, Model\n",
    "from sklearn.metrics import precision_score, accuracy_score\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "\n",
    "CIFAR_ROOT = os.path.join('..', 'data')\n",
    "CIFAR10_PATH = os.path.join(CIFAR_ROOT, 'cifar-10-batches-py')\n",
    "\n",
    "HISTORY_FILE = os.path.join(CIFAR10_PATH, 'cifar10_history.csv')\n",
    "WEIGHT_FILE = os.path.join(CIFAR10_PATH, 'cifar10_weight.pth')\n",
    "\n",
    "HISTORY1_FILE = os.path.join(CIFAR10_PATH, 'cifar10_history1.csv')\n",
    "HISTORY2_FILE = os.path.join(CIFAR10_PATH, 'cifar10_history2.csv')\n",
    "\n",
    "WEIGHT1_FILE = os.path.join(CIFAR10_PATH, 'cifar10_weight1.pth')\n",
    "WEIGHT2_FILE = os.path.join(CIFAR10_PATH, 'cifar10_weight2.pth')\n",
    "\n",
    "NB_CLASSES = 10\n",
    "NROWS = 8\n",
    "\n",
    "IMAGE_MEAN = 0.5\n",
    "IMAGE_STD = 0.5\n",
    "IMAGE_SIZE = 32\n",
    "IMAGE_CHANNEL = 3\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "VAL_BATCH_SIZE = 64\n",
    "LR = 1e-3"
   ]
  },
  {
   "source": [
    "### common codes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "def plot_metric(dfhistory, metric):\n",
    "    train_metrics = dfhistory[metric]\n",
    "    val_metrics = dfhistory['val_'+metric]\n",
    "    epochs = range(1, len(train_metrics) + 1)\n",
    "    plt.plot(epochs, train_metrics, 'bo--')\n",
    "    plt.plot(epochs, val_metrics, 'ro-')\n",
    "    plt.title('Training and validation '+ metric)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([\"train_\"+metric, 'valid_'+metric])\n",
    "    plt.show()\n",
    "\n",
    "def plot_images(features, mean=0.5, std=0.5, nrows=8, figsize=(2, 2)):\n",
    "    # images: tensor (B, C, H, W), grid_image: ndarray (C, H, W)\n",
    "    grid_image = utils.make_grid(features, nrow=nrows).numpy()\n",
    "    grid_image = mean + grid_image * std\n",
    "\n",
    "    # imshow (H, W, C)\n",
    "    grid_image = grid_image.transpose(1, 2, 0)\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(grid_image)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()\n",
    "\n",
    "# save and load\n",
    "def save_history(model, file, mode='csv'):\n",
    "    assert mode == 'csv'\n",
    "    assert type(model.history) is pd.DataFrame\n",
    "    model.history.to_csv(file)\n",
    "\n",
    "def save_weight(model, file):\n",
    "    weights = dict()\n",
    "    weights.update({'epoch': model.epoch})\n",
    "    weights.update({'net': model.state_dict()})\n",
    "    weights.update({'optimizer': model.optim.state_dict()})\n",
    "    torch.save(weights, file)\n",
    "\n",
    "def load_history(file, index_col='epoch', mode='csv'):\n",
    "    assert mode == 'csv'\n",
    "    return pd.read_csv(file, index_col=index_col)\n",
    "\n",
    "def load_weight(model, file, net_only=False):\n",
    "    weights = torch.load(file)\n",
    "    model.load_state_dict(weights['net'])\n",
    "    if not net_only:\n",
    "        model.epoch = weights.get('epoch', 0)\n",
    "        model.optim.load_state_dict(weights['optimizer'])\n",
    "    return model\n",
    "\n",
    "# metrics\n",
    "def precision_metrics(targets, labels):\n",
    "    # targets (-1, C), labels (-1)\n",
    "    y_pred = targets.data.max(1)[1].numpy()\n",
    "    y_true = labels.numpy()\n",
    "    score = precision_score(y_true, y_pred, average='macro')\n",
    "    # return (1)\n",
    "    return torch.tensor(score)\n",
    "\n",
    "def accuracy_metrics(targets, labels):\n",
    "    # targets (-1, C), labels (-1)\n",
    "    y_pred = targets.data.max(1)[1].numpy()\n",
    "    y_true = labels.numpy()\n",
    "    score = accuracy_score(y_true, y_pred)\n",
    "    # return (1)\n",
    "    return torch.tensor(score)\n",
    "\n",
    "# training functions\n",
    "def run_step(model, features, labels, train_mode=True):\n",
    "    targets = model(features)\n",
    "    \n",
    "    metrics = dict()\n",
    "    loss = model.loss_fn(targets, labels)\n",
    "    metrics.update({'%sloss' % ('' if train_mode else 'val_'): loss.item()})\n",
    "    \n",
    "    for metric_name, metric_fn in model.metrics_dict.items():\n",
    "        metric_value = metric_fn(targets, labels)\n",
    "        metrics.update({'%s%s' % ('' if train_mode else 'val_', metric_name): metric_value.item()})\n",
    "\n",
    "    loss.backward()\n",
    "    model.optim.step()\n",
    "    model.optim.zero_grad()\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def run_epoch(model, dataloader, train_mode=True, log_per_steps=200):\n",
    "    metrics_epoch = dict()\n",
    "\n",
    "    model.train(train_mode)\n",
    "    for step, (features, labels) in enumerate(dataloader, 1):\n",
    "        metrics = run_step(model, features, labels, train_mode)\n",
    "\n",
    "        # # update loss_epoch (mean)\n",
    "        # loss_epoch = (step - 1) / step * loss_epoch + metric_val / step\n",
    "        # update metric_epoch (mean)\n",
    "        for metric_name, metric_val in metrics.items():\n",
    "            if metrics_epoch.get(metric_name) == None:\n",
    "                metrics_epoch[metric_name] = metric_val\n",
    "            else:\n",
    "                metrics_epoch[metric_name] = \\\n",
    "                    (step - 1) / step * metrics_epoch[metric_name] + metric_val / step\n",
    "\n",
    "        if step % log_per_steps == 0:\n",
    "            print(\" - Step %d, %s\" % (step, metrics_epoch))\n",
    "\n",
    "    return metrics_epoch\n",
    "\n",
    "def train_model(model, dataloader_train, dataloader_valid, epochs, log_per_epochs=10, log_per_steps=200):\n",
    "    print(\"==========\" * 6)\n",
    "    print(\"= Training model\")\n",
    "    \n",
    "    metrics_list = []\n",
    "    start_epoch = 1 + model.epoch\n",
    "    end_epoch = epochs + 1 + model.epoch\n",
    "    for epoch in range(start_epoch, end_epoch):\n",
    "        metrics = dict()\n",
    "        print(\"==========\" * 6)\n",
    "        print(\"= Epoch %d/%d @ %s\" % (epoch, end_epoch - 1, datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')))\n",
    "        metrics_train = run_epoch(model, dataloader_train, train_mode=True, log_per_steps=log_per_steps)\n",
    "        metrics_valid = run_epoch(model, dataloader_valid, train_mode=False, log_per_steps=log_per_steps)\n",
    "        metrics.update({'epoch': epoch})\n",
    "        metrics.update(metrics_train)\n",
    "        metrics.update(metrics_valid)\n",
    "        metrics_list.append(metrics)\n",
    "\n",
    "        model.epoch = epoch\n",
    "\n",
    "        if epoch % log_per_epochs == 0:\n",
    "            print('= %s' % metrics)\n",
    "        \n",
    "    print(\"==========\" * 6)\n",
    "    \n",
    "    model.history = pd.DataFrame(metrics_list)\n",
    "    model.history.set_index('epoch', inplace=True)\n",
    "    return model.history\n",
    "\n",
    "def predict_model(model, features):\n",
    "    model.eval()\n",
    "    targets = model(features)\n",
    "    \n",
    "    return targets.data.max(1)[1]\n",
    "\n",
    "def eval_model(model, features, labels):\n",
    "    model.eval()\n",
    "    targets = model(features)\n",
    "\n",
    "    metrics = dict()\n",
    "    for metric_name, metric_fn in model.metrics_dict.items():\n",
    "        metric_value = metric_fn(targets, labels)\n",
    "        metrics.update({metric_name: metric_value.item()})\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "source": [
    "### datasets and dataloader"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# datasets and dataloader\n",
    "data_tf = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomGrayscale(),\n",
    "    transforms.ToTensor(),  # 0~255 -> 0~1\n",
    "    transforms.Normalize(IMAGE_MEAN, IMAGE_STD) # 0~1 -> -1~1\n",
    "])\n",
    "\n",
    "ds_train = datasets.CIFAR10(CIFAR_ROOT, train=True, transform=data_tf, download=True)\n",
    "ds_valid = datasets.CIFAR10(CIFAR_ROOT, train=False, transform=data_tf, download=True)\n",
    "\n",
    "dl_train = data.DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "dl_valid = data.DataLoader(ds_valid, batch_size=VAL_BATCH_SIZE, shuffle=True)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "source": [
    "### batch sample plot (optional)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch sample plot\n",
    "batch_features, _ = next(iter(dl_train))\n",
    "\n",
    "plot_images(batch_features, mean=IMAGE_MEAN, std=IMAGE_STD, nrows=NROWS, figsize=(8, 8))"
   ]
  },
  {
   "source": [
    "### network class"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleVGG16(nn.Module):\n",
    "    def __init__(self, classes=10, *args, **kwargs):\n",
    "        super(SimpleVGG16, self).__init__(*args, **kwargs)\n",
    "        self.epoch = 0\n",
    "        \n",
    "        self.vgg16 = models.vgg16(pretrained=True)\n",
    "        self._freeze_vgg16()\n",
    "        \n",
    "        self.fc1 = nn.Linear(1000, classes)\n",
    "        self.logsoftmax1 = nn.LogSoftmax(1)\n",
    "\n",
    "    def _freeze_vgg16(self):\n",
    "        for param in self.vgg16.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, input):\n",
    "        input = self.vgg16(input)\n",
    "        input = self.fc1(input)\n",
    "        input = self.logsoftmax1(input)\n",
    "        return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1           [-1, 64, 32, 32]           1,792\n              ReLU-2           [-1, 64, 32, 32]               0\n            Conv2d-3           [-1, 64, 32, 32]          36,928\n              ReLU-4           [-1, 64, 32, 32]               0\n         MaxPool2d-5           [-1, 64, 16, 16]               0\n            Conv2d-6          [-1, 128, 16, 16]          73,856\n              ReLU-7          [-1, 128, 16, 16]               0\n            Conv2d-8          [-1, 128, 16, 16]         147,584\n              ReLU-9          [-1, 128, 16, 16]               0\n        MaxPool2d-10            [-1, 128, 8, 8]               0\n           Conv2d-11            [-1, 256, 8, 8]         295,168\n             ReLU-12            [-1, 256, 8, 8]               0\n           Conv2d-13            [-1, 256, 8, 8]         590,080\n             ReLU-14            [-1, 256, 8, 8]               0\n           Conv2d-15            [-1, 256, 8, 8]         590,080\n             ReLU-16            [-1, 256, 8, 8]               0\n        MaxPool2d-17            [-1, 256, 4, 4]               0\n           Conv2d-18            [-1, 512, 4, 4]       1,180,160\n             ReLU-19            [-1, 512, 4, 4]               0\n           Conv2d-20            [-1, 512, 4, 4]       2,359,808\n             ReLU-21            [-1, 512, 4, 4]               0\n           Conv2d-22            [-1, 512, 4, 4]       2,359,808\n             ReLU-23            [-1, 512, 4, 4]               0\n        MaxPool2d-24            [-1, 512, 2, 2]               0\n           Conv2d-25            [-1, 512, 2, 2]       2,359,808\n             ReLU-26            [-1, 512, 2, 2]               0\n           Conv2d-27            [-1, 512, 2, 2]       2,359,808\n             ReLU-28            [-1, 512, 2, 2]               0\n           Conv2d-29            [-1, 512, 2, 2]       2,359,808\n             ReLU-30            [-1, 512, 2, 2]               0\n        MaxPool2d-31            [-1, 512, 1, 1]               0\nAdaptiveAvgPool2d-32            [-1, 512, 7, 7]               0\n           Linear-33                 [-1, 4096]     102,764,544\n             ReLU-34                 [-1, 4096]               0\n          Dropout-35                 [-1, 4096]               0\n           Linear-36                 [-1, 4096]      16,781,312\n             ReLU-37                 [-1, 4096]               0\n          Dropout-38                 [-1, 4096]               0\n           Linear-39                 [-1, 1000]       4,097,000\n           Linear-40                   [-1, 10]          10,010\n       LogSoftmax-41                   [-1, 10]               0\n================================================================\nTotal params: 138,367,554\nTrainable params: 10,010\nNon-trainable params: 138,357,544\n----------------------------------------------------------------\nInput size (MB): 0.011719\nForward/backward pass size (MB): 4.843719\nParams size (MB): 527.830330\nEstimated Total Size (MB): 532.685768\n----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "Model(SimpleVGG16()).summary(input_shape=(3, 32, 32))"
   ]
  },
  {
   "source": [
    "### model training and save history and weights"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "12775733, 'accuracy': 0.09732717041800633}\n",
      " - Step 1556, {'loss': 649398.4878369335, 'precision': 0.011981017639624135, 'accuracy': 0.09734495501285337}\n",
      " - Step 1557, {'loss': 648981.4062339725, 'precision': 0.011979343896759894, 'accuracy': 0.0973426461143223}\n",
      " - Step 1558, {'loss': 648564.8599749976, 'precision': 0.011978340894686664, 'accuracy': 0.09734034017971747}\n",
      " - Step 1559, {'loss': 648148.8481083694, 'precision': 0.011974666525928046, 'accuracy': 0.09731799230275806}\n",
      " - Step 1560, {'loss': 647733.3695559306, 'precision': 0.011978119375021112, 'accuracy': 0.0973557692307691}\n",
      " - Step 1561, {'loss': 647318.4233520082, 'precision': 0.011980455621417639, 'accuracy': 0.0973934977578474}\n",
      " - Step 1562, {'loss': 646904.0084335804, 'precision': 0.011982788876461545, 'accuracy': 0.0974311779769525}\n",
      " - Step 1563, {'loss': 646490.1239987983, 'precision': 0.011984008390225094, 'accuracy': 0.09744881637875867}\n",
      " - Step 1, {'val_loss': 2.338932991027832, 'val_precision': 0.0078125, 'val_accuracy': 0.078125}\n",
      " - Step 2, {'val_loss': 2.3179450035095215, 'val_precision': 0.009375, 'val_accuracy': 0.09375}\n",
      " - Step 3, {'val_loss': 2.3596156438191733, 'val_precision': 0.007812499999999999, 'val_accuracy': 0.078125}\n",
      " - Step 4, {'val_loss': 2.3605781197547913, 'val_precision': 0.008593749999999999, 'val_accuracy': 0.0859375}\n",
      " - Step 5, {'val_loss': 2.3740944385528566, 'val_precision': 0.008749999999999999, 'val_accuracy': 0.08750000000000001}\n",
      " - Step 6, {'val_loss': 2.3778574466705322, 'val_precision': 0.008333333333333333, 'val_accuracy': 0.08333333333333334}\n",
      " - Step 7, {'val_loss': 2.369387796946934, 'val_precision': 0.009598214285714286, 'val_accuracy': 0.09598214285714286}\n",
      " - Step 8, {'val_loss': 2.3649483919143672, 'val_precision': 0.0095703125, 'val_accuracy': 0.095703125}\n",
      " - Step 9, {'val_loss': 2.3638075722588425, 'val_precision': 0.009722222222222222, 'val_accuracy': 0.09722222222222221}\n",
      " - Step 10, {'val_loss': 2.365475058555602, 'val_precision': 0.00984375, 'val_accuracy': 0.0984375}\n",
      " - Step 11, {'val_loss': 2.363179076801646, 'val_precision': 0.009517045454545455, 'val_accuracy': 0.09517045454545453}\n",
      " - Step 12, {'val_loss': 2.362409532070159, 'val_precision': 0.009895833333333333, 'val_accuracy': 0.09895833333333331}\n",
      " - Step 13, {'val_loss': 2.365852209237905, 'val_precision': 0.009615384615384616, 'val_accuracy': 0.09615384615384615}\n",
      " - Step 14, {'val_loss': 2.363958835601806, 'val_precision': 0.00970982142857143, 'val_accuracy': 0.09709821428571429}\n",
      " - Step 15, {'val_loss': 2.3599032402038573, 'val_precision': 0.010000000000000002, 'val_accuracy': 0.09999999999999999}\n",
      " - Step 16, {'val_loss': 2.3655963838100433, 'val_precision': 0.0095703125, 'val_accuracy': 0.09570312499999999}\n",
      " - Step 17, {'val_loss': 2.3728498290566837, 'val_precision': 0.009558823529411765, 'val_accuracy': 0.09558823529411763}\n",
      " - Step 18, {'val_loss': 2.370584726333618, 'val_precision': 0.009288194444444446, 'val_accuracy': 0.09288194444444443}\n",
      " - Step 19, {'val_loss': 2.369772710298237, 'val_precision': 0.009375000000000001, 'val_accuracy': 0.09374999999999999}\n",
      " - Step 20, {'val_loss': 2.367376899719238, 'val_precision': 0.009375000000000001, 'val_accuracy': 0.09374999999999999}\n",
      " - Step 21, {'val_loss': 2.3714419319516136, 'val_precision': 0.009449404761904763, 'val_accuracy': 0.0944940476190476}\n",
      " - Step 22, {'val_loss': 2.373574896292253, 'val_precision': 0.009517045454545457, 'val_accuracy': 0.09517045454545453}\n",
      " - Step 23, {'val_loss': 2.374691165011862, 'val_precision': 0.009510869565217394, 'val_accuracy': 0.0951086956521739}\n",
      " - Step 24, {'val_loss': 2.3743246495723724, 'val_precision': 0.009505208333333336, 'val_accuracy': 0.09505208333333333}\n",
      " - Step 25, {'val_loss': 2.3718655300140377, 'val_precision': 0.009437500000000003, 'val_accuracy': 0.094375}\n",
      " - Step 26, {'val_loss': 2.37102525967818, 'val_precision': 0.009675480769230771, 'val_accuracy': 0.0967548076923077}\n",
      " - Step 27, {'val_loss': 2.371729100192034, 'val_precision': 0.009548611111111114, 'val_accuracy': 0.0954861111111111}\n",
      " - Step 28, {'val_loss': 2.370382743222372, 'val_precision': 0.009765625000000002, 'val_accuracy': 0.09765624999999999}\n",
      " - Step 29, {'val_loss': 2.368728917220542, 'val_precision': 0.009752155172413795, 'val_accuracy': 0.09752155172413793}\n",
      " - Step 30, {'val_loss': 2.369130039215087, 'val_precision': 0.009791666666666669, 'val_accuracy': 0.09791666666666667}\n",
      " - Step 31, {'val_loss': 2.367889442751484, 'val_precision': 0.009979838709677422, 'val_accuracy': 0.09979838709677419}\n",
      " - Step 32, {'val_loss': 2.364262975752353, 'val_precision': 0.010058593750000002, 'val_accuracy': 0.1005859375}\n",
      " - Step 33, {'val_loss': 2.363451704834446, 'val_precision': 0.010085227272727275, 'val_accuracy': 0.10085227272727272}\n",
      " - Step 34, {'val_loss': 2.364213740124421, 'val_precision': 0.010018382352941177, 'val_accuracy': 0.10018382352941177}\n",
      " - Step 35, {'val_loss': 2.36481545312064, 'val_precision': 0.010089285714285716, 'val_accuracy': 0.10089285714285715}\n",
      " - Step 36, {'val_loss': 2.3631475236680766, 'val_precision': 0.010112847222222224, 'val_accuracy': 0.10112847222222222}\n",
      " - Step 37, {'val_loss': 2.362364923631822, 'val_precision': 0.00996621621621622, 'val_accuracy': 0.09966216216216216}\n",
      " - Step 38, {'val_loss': 2.3608140819951102, 'val_precision': 0.010032894736842109, 'val_accuracy': 0.10032894736842105}\n",
      " - Step 39, {'val_loss': 2.35893450027857, 'val_precision': 0.010136217948717953, 'val_accuracy': 0.10136217948717947}\n",
      " - Step 40, {'val_loss': 2.3582827508449546, 'val_precision': 0.010078125000000002, 'val_accuracy': 0.10078124999999999}\n",
      " - Step 41, {'val_loss': 2.362014241334868, 'val_precision': 0.010022865853658539, 'val_accuracy': 0.10022865853658536}\n",
      " - Step 42, {'val_loss': 2.3614465111777885, 'val_precision': 0.010156250000000002, 'val_accuracy': 0.10156249999999999}\n",
      " - Step 43, {'val_loss': 2.3629052195438107, 'val_precision': 0.010065406976744188, 'val_accuracy': 0.10065406976744184}\n",
      " - Step 44, {'val_loss': 2.3623730052601197, 'val_precision': 0.009978693181818182, 'val_accuracy': 0.09978693181818181}\n",
      " - Step 45, {'val_loss': 2.3609944767422135, 'val_precision': 0.009930555555555555, 'val_accuracy': 0.09930555555555554}\n",
      " - Step 46, {'val_loss': 2.3599165367043526, 'val_precision': 0.009918478260869565, 'val_accuracy': 0.09918478260869563}\n",
      " - Step 47, {'val_loss': 2.3624587109748343, 'val_precision': 0.009940159574468085, 'val_accuracy': 0.09940159574468083}\n",
      " - Step 48, {'val_loss': 2.3622329185406357, 'val_precision': 0.009993489583333333, 'val_accuracy': 0.09993489583333331}\n",
      " - Step 49, {'val_loss': 2.36198152328024, 'val_precision': 0.010012755102040815, 'val_accuracy': 0.10012755102040814}\n",
      " - Step 50, {'val_loss': 2.3607059812545765, 'val_precision': 0.010187499999999999, 'val_accuracy': 0.10187499999999998}\n",
      " - Step 51, {'val_loss': 2.359365397808597, 'val_precision': 0.010049019607843135, 'val_accuracy': 0.10049019607843135}\n",
      " - Step 52, {'val_loss': 2.35827594078504, 'val_precision': 0.010036057692307688, 'val_accuracy': 0.10036057692307689}\n",
      " - Step 53, {'val_loss': 2.3583898229419047, 'val_precision': 0.010023584905660373, 'val_accuracy': 0.10023584905660374}\n",
      " - Step 54, {'val_loss': 2.359233008490667, 'val_precision': 0.010040509259259256, 'val_accuracy': 0.10040509259259256}\n",
      " - Step 55, {'val_loss': 2.359563502398403, 'val_precision': 0.010110479797979795, 'val_accuracy': 0.1008522727272727}\n",
      " - Step 56, {'val_loss': 2.3588024462972355, 'val_precision': 0.010041542658730156, 'val_accuracy': 0.10016741071428567}\n",
      " - Step 57, {'val_loss': 2.3579709780843623, 'val_precision': 0.010057261208576996, 'val_accuracy': 0.100328947368421}\n",
      " - Step 58, {'val_loss': 2.3576197747526484, 'val_precision': 0.009991618773946357, 'val_accuracy': 0.09967672413793098}\n",
      " - Step 59, {'val_loss': 2.3570702278007882, 'val_precision': 0.010007650659133708, 'val_accuracy': 0.0998411016949152}\n",
      " - Step 60, {'val_loss': 2.356607894102731, 'val_precision': 0.009997106481481478, 'val_accuracy': 0.09973958333333327}\n",
      " - Step 61, {'val_loss': 2.3554050570628666, 'val_precision': 0.010140596539162109, 'val_accuracy': 0.10117827868852453}\n",
      " - Step 62, {'val_loss': 2.3549751735502658, 'val_precision': 0.010027441756272397, 'val_accuracy': 0.10005040322580638}\n",
      " - Step 63, {'val_loss': 2.3545218611520418, 'val_precision': 0.010017085537918866, 'val_accuracy': 0.09995039682539675}\n",
      " - Step 64, {'val_loss': 2.354094520211218, 'val_precision': 0.009909396701388884, 'val_accuracy': 0.09887695312499992}\n",
      " - Step 65, {'val_loss': 2.353399361096894, 'val_precision': 0.009829059829059824, 'val_accuracy': 0.09807692307692299}\n",
      " - Step 66, {'val_loss': 2.3527463638421247, 'val_precision': 0.009869528619528613, 'val_accuracy': 0.0984848484848484}\n",
      " - Step 67, {'val_loss': 2.3523285211022205, 'val_precision': 0.009885468490878933, 'val_accuracy': 0.0986473880597014}\n",
      " - Step 68, {'val_loss': 2.351776196676141, 'val_precision': 0.009854983660130713, 'val_accuracy': 0.09834558823529403}\n",
      " - Step 69, {'val_loss': 2.351147993751193, 'val_precision': 0.009870672302737514, 'val_accuracy': 0.09850543478260862}\n",
      " - Step 70, {'val_loss': 2.351292773655482, 'val_precision': 0.009863591269841265, 'val_accuracy': 0.09843749999999993}\n",
      " - Step 71, {'val_loss': 2.3504461536944743, 'val_precision': 0.009900723787167444, 'val_accuracy': 0.09881161971830979}\n",
      " - Step 72, {'val_loss': 2.349608444505267, 'val_precision': 0.010023630401234565, 'val_accuracy': 0.10004340277777772}\n",
      " - Step 73, {'val_loss': 2.3495727271249844, 'val_precision': 0.009993340943683407, 'val_accuracy': 0.09974315068493145}\n",
      " - Step 74, {'val_loss': 2.3488560238400016, 'val_precision': 0.010090559309309306, 'val_accuracy': 0.10071790540540534}\n",
      " - Step 75, {'val_loss': 2.3482456874847406, 'val_precision': 0.010143518518518515, 'val_accuracy': 0.10124999999999995}\n",
      " - Step 76, {'val_loss': 2.3475883069791283, 'val_precision': 0.010071728801169586, 'val_accuracy': 0.10053453947368417}\n",
      " - Step 77, {'val_loss': 2.3468421620207938, 'val_precision': 0.010082972582972577, 'val_accuracy': 0.1006493506493506}\n",
      " - Step 78, {'val_loss': 2.3462735934135233, 'val_precision': 0.010154024216524211, 'val_accuracy': 0.10136217948717943}\n",
      " - Step 79, {'val_loss': 2.3466662243951717, 'val_precision': 0.010065049226441627, 'val_accuracy': 0.10047468354430375}\n",
      " - Step 80, {'val_loss': 2.3462910830974573, 'val_precision': 0.010095486111111107, 'val_accuracy': 0.10078124999999995}\n",
      " - Step 81, {'val_loss': 2.3459112026073305, 'val_precision': 0.010067301097393686, 'val_accuracy': 0.10050154320987649}\n",
      " - Step 82, {'val_loss': 2.3455294138047744, 'val_precision': 0.010058858401084007, 'val_accuracy': 0.10041920731707311}\n",
      " - Step 83, {'val_loss': 2.3463006249393312, 'val_precision': 0.010012968540829982, 'val_accuracy': 0.0999623493975903}\n",
      " - Step 84, {'val_loss': 2.3468399615514834, 'val_precision': 0.010023974867724864, 'val_accuracy': 0.1000744047619047}\n",
      " - Step 85, {'val_loss': 2.3463007057414327, 'val_precision': 0.010053104575163395, 'val_accuracy': 0.10036764705882346}\n",
      " - Step 86, {'val_loss': 2.3454300775084373, 'val_precision': 0.010158268733850125, 'val_accuracy': 0.10119912790697669}\n",
      " - Step 87, {'val_loss': 2.3450140267953095, 'val_precision': 0.010131305874840353, 'val_accuracy': 0.10093390804597696}\n",
      " - Step 88, {'val_loss': 2.3456118540330357, 'val_precision': 0.010158222853535348, 'val_accuracy': 0.10120738636363631}\n",
      " - Step 89, {'val_loss': 2.345706398567456, 'val_precision': 0.01013186641697877, 'val_accuracy': 0.10094803370786512}\n",
      " - Step 90, {'val_loss': 2.345680748091803, 'val_precision': 0.010158179012345673, 'val_accuracy': 0.10121527777777772}\n",
      " - Step 91, {'val_loss': 2.34534725514087, 'val_precision': 0.010149572649572643, 'val_accuracy': 0.1011332417582417}\n",
      " - Step 92, {'val_loss': 2.3451181883397303, 'val_precision': 0.010124169685990331, 'val_accuracy': 0.10088315217391298}\n",
      " - Step 93, {'val_loss': 2.3449007490629783, 'val_precision': 0.010065710872162478, 'val_accuracy': 0.10030241935483865}\n",
      " - Step 94, {'val_loss': 2.344614883686633, 'val_precision': 0.010074985224586282, 'val_accuracy': 0.10039893617021271}\n",
      " - Step 95, {'val_loss': 2.3444756181616526, 'val_precision': 0.010100511695906426, 'val_accuracy': 0.10065789473684206}\n",
      " - Step 96, {'val_loss': 2.3441406836112333, 'val_precision': 0.010158058449074067, 'val_accuracy': 0.10123697916666663}\n",
      " - Step 97, {'val_loss': 2.343886264820688, 'val_precision': 0.01016609392898052, 'val_accuracy': 0.10132087628865975}\n",
      " - Step 98, {'val_loss': 2.34352045399802, 'val_precision': 0.010158021541950106, 'val_accuracy': 0.10124362244897955}\n",
      " - Step 99, {'val_loss': 2.3431023130513196, 'val_precision': 0.01016589506172839, 'val_accuracy': 0.10132575757575754}\n",
      " - Step 100, {'val_loss': 2.343161149024963, 'val_precision': 0.010173611111111105, 'val_accuracy': 0.10140624999999998}\n",
      " - Step 101, {'val_loss': 2.343592957694931, 'val_precision': 0.010150233773377332, 'val_accuracy': 0.1011757425742574}\n",
      " - Step 102, {'val_loss': 2.3438264786028387, 'val_precision': 0.010081358932461868, 'val_accuracy': 0.10049019607843135}\n",
      " - Step 103, {'val_loss': 2.343517065048217, 'val_precision': 0.010028991370010783, 'val_accuracy': 0.09996966019417475}\n",
      " - Step 104, {'val_loss': 2.343858138873026, 'val_precision': 0.00999265491452991, 'val_accuracy': 0.09960937499999999}\n",
      " - Step 105, {'val_loss': 2.3441368602571027, 'val_precision': 0.010001653439153435, 'val_accuracy': 0.09970238095238095}\n",
      " - Step 106, {'val_loss': 2.3451771848606606, 'val_precision': 0.009981001048218027, 'val_accuracy': 0.09949882075471697}\n",
      " - Step 107, {'val_loss': 2.34541672189659, 'val_precision': 0.009989940290758044, 'val_accuracy': 0.0995911214953271}\n",
      " - Step 108, {'val_loss': 2.3447833922174235, 'val_precision': 0.010027649176954728, 'val_accuracy': 0.09997106481481481}\n",
      " - Step 109, {'val_loss': 2.344781602194549, 'val_precision': 0.010007326707441382, 'val_accuracy': 0.09977064220183487}\n",
      " - Step 110, {'val_loss': 2.3444609620354386, 'val_precision': 0.010015782828282823, 'val_accuracy': 0.09985795454545456}\n",
      " - Step 111, {'val_loss': 2.3442378430753132, 'val_precision': 0.010010010010010005, 'val_accuracy': 0.09980292792792794}\n",
      " - Step 112, {'val_loss': 2.344448540891919, 'val_precision': 0.010004340277777772, 'val_accuracy': 0.09974888392857145}\n",
      " - Step 113, {'val_loss': 2.3447674017036904, 'val_precision': 0.00998494346116027, 'val_accuracy': 0.09955752212389384}\n",
      " - Step 114, {'val_loss': 2.345402102721364, 'val_precision': 0.00997959307992202, 'val_accuracy': 0.09950657894736845}\n",
      " - Step 115, {'val_loss': 2.3452337472335145, 'val_precision': 0.010001509661835743, 'val_accuracy': 0.09972826086956524}\n",
      " - Step 116, {'val_loss': 2.3447777094512143, 'val_precision': 0.01003651819923371, 'val_accuracy': 0.10008081896551727}\n",
      " - Step 117, {'val_loss': 2.3450043445978404, 'val_precision': 0.01004421889838556, 'val_accuracy': 0.10016025641025643}\n",
      " - Step 118, {'val_loss': 2.345906627380241, 'val_precision': 0.009998822975517886, 'val_accuracy': 0.099708686440678}\n",
      " - Step 119, {'val_loss': 2.3456532875028975, 'val_precision': 0.009980450513538745, 'val_accuracy': 0.09952731092436978}\n",
      " - Step 120, {'val_loss': 2.345654028654098, 'val_precision': 0.009949363425925922, 'val_accuracy': 0.09921875000000004}\n",
      " - Step 121, {'val_loss': 2.3454660265898895, 'val_precision': 0.009996269513314964, 'val_accuracy': 0.09969008264462814}\n",
      " - Step 122, {'val_loss': 2.3461625986411914, 'val_precision': 0.010016791894353366, 'val_accuracy': 0.0998975409836066}\n",
      " - Step 123, {'val_loss': 2.345695420009333, 'val_precision': 0.01003698057813911, 'val_accuracy': 0.10010162601626021}\n",
      " - Step 124, {'val_loss': 2.3457595398349143, 'val_precision': 0.010132448476702504, 'val_accuracy': 0.10105846774193554}\n",
      " - Step 125, {'val_loss': 2.3465748996734614, 'val_precision': 0.010088888888888883, 'val_accuracy': 0.10062500000000006}\n",
      " - Step 126, {'val_loss': 2.3465071859813866, 'val_precision': 0.010083223104056432, 'val_accuracy': 0.10057043650793657}\n",
      " - Step 127, {'val_loss': 2.346966259122833, 'val_precision': 0.010077646544181973, 'val_accuracy': 0.10051673228346462}\n",
      " - Step 128, {'val_loss': 2.3467497993260618, 'val_precision': 0.01012098524305555, 'val_accuracy': 0.10095214843750006}\n",
      " - Step 129, {'val_loss': 2.3461213795713673, 'val_precision': 0.010163652024117136, 'val_accuracy': 0.10138081395348843}\n",
      " - Step 130, {'val_loss': 2.34586276274461, 'val_precision': 0.010157585470085466, 'val_accuracy': 0.10132211538461544}\n",
      " - Step 131, {'val_loss': 2.3464274315433644, 'val_precision': 0.010127756573367256, 'val_accuracy': 0.10102576335877868}\n",
      " - Step 132, {'val_loss': 2.3478613911253032, 'val_precision': 0.010110216750841746, 'val_accuracy': 0.10085227272727278}\n",
      " - Step 133, {'val_loss': 2.3480234504642343, 'val_precision': 0.010116436925647447, 'val_accuracy': 0.10091635338345868}\n",
      " - Step 134, {'val_loss': 2.3478821871885613, 'val_precision': 0.010122564262023213, 'val_accuracy': 0.10097947761194033}\n",
      " - Step 135, {'val_loss': 2.3475238552799933, 'val_precision': 0.01011702674897119, 'val_accuracy': 0.10092592592592595}\n",
      " - Step 136, {'val_loss': 2.347079164841596, 'val_precision': 0.010111570669934638, 'val_accuracy': 0.1008731617647059}\n",
      " - Step 137, {'val_loss': 2.3469795275778664, 'val_precision': 0.010083384022708837, 'val_accuracy': 0.10059306569343068}\n",
      " - Step 138, {'val_loss': 2.3468235592911206, 'val_precision': 0.010078250805152976, 'val_accuracy': 0.1005434782608696}\n",
      " - Step 139, {'val_loss': 2.346599400472298, 'val_precision': 0.010050709432454034, 'val_accuracy': 0.1002697841726619}\n",
      " - Step 140, {'val_loss': 2.3464097346578328, 'val_precision': 0.010057043650793648, 'val_accuracy': 0.10033482142857146}\n",
      " - Step 141, {'val_loss': 2.3460856532374175, 'val_precision': 0.010074369582348303, 'val_accuracy': 0.10050975177304967}\n",
      " - Step 142, {'val_loss': 2.3458399990914574, 'val_precision': 0.010091451486697963, 'val_accuracy': 0.10068221830985918}\n",
      " - Step 143, {'val_loss': 2.345480061911203, 'val_precision': 0.010097367909867908, 'val_accuracy': 0.10074300699300702}\n",
      " - Step 144, {'val_loss': 2.3454244765970444, 'val_precision': 0.010103202160493825, 'val_accuracy': 0.10080295138888891}\n",
      " - Step 145, {'val_loss': 2.345078338425735, 'val_precision': 0.010098180076628351, 'val_accuracy': 0.1007543103448276}\n",
      " - Step 146, {'val_loss': 2.3448021575196147, 'val_precision': 0.010114630898021308, 'val_accuracy': 0.10092037671232877}\n",
      " - Step 147, {'val_loss': 2.3446553450863377, 'val_precision': 0.0101521164021164, 'val_accuracy': 0.10129676870748298}\n",
      " - Step 148, {'val_loss': 2.3450449109077454, 'val_precision': 0.010146865615615612, 'val_accuracy': 0.10124577702702701}\n",
      " - Step 149, {'val_loss': 2.344715777659576, 'val_precision': 0.01015217188665175, 'val_accuracy': 0.10130033557046979}\n",
      " - Step 150, {'val_loss': 2.344381411870321, 'val_precision': 0.010146990740740738, 'val_accuracy': 0.10124999999999998}\n",
      " - Step 151, {'val_loss': 2.34426984565937, 'val_precision': 0.010121182855040467, 'val_accuracy': 0.10099337748344368}\n",
      " - Step 152, {'val_loss': 2.3441389501094823, 'val_precision': 0.01010599415204678, 'val_accuracy': 0.10084292763157893}\n",
      " - Step 153, {'val_loss': 2.3440048881605566, 'val_precision': 0.010131853667392879, 'val_accuracy': 0.10110294117647056}\n",
      " - Step 154, {'val_loss': 2.3438430745880336, 'val_precision': 0.010126939033189028, 'val_accuracy': 0.10105519480519479}\n",
      " - Step 155, {'val_loss': 2.3441105319607654, 'val_precision': 0.010122087813620067, 'val_accuracy': 0.10100806451612902}\n",
      " - Step 156, {'val_loss': 2.34385933325841, 'val_precision': 0.010137330840455837, 'val_accuracy': 0.10116185897435896}\n",
      " - Step 157, {'val_loss': 2.3442729142061474, 'val_precision': 0.010122523000707711, 'val_accuracy': 0.10091560509554139}\n",
      "= {'epoch': 1, 'loss': 646490.1239987983, 'precision': 0.011984008390225094, 'accuracy': 0.09744881637875867, 'val_loss': 2.3442729142061474, 'val_precision': 0.010122523000707711, 'val_accuracy': 0.10091560509554139}\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# training settings (loss, optim & metrics)\n",
    "model = SimpleVGG16(NB_CLASSES)\n",
    "model.loss_fn = nn.CrossEntropyLoss()\n",
    "model.optim = optim.Adam(model.parameters(), lr=LR)\n",
    "model.metrics_dict = {\n",
    "    'precision': precision_metrics,\n",
    "    'accuracy': accuracy_metrics\n",
    "}\n",
    "\n",
    "# model training\n",
    "history = train_model(model, dl_train, dl_valid, epochs=20, log_per_epochs=1, log_per_steps=200)\n",
    "\n",
    "# save training history\n",
    "save_history(model, HISTORY1_FILE)\n",
    "\n",
    "# save weights\n",
    "save_weight(model, WEIGHT1_FILE)"
   ]
  },
  {
   "source": [
    "### re-training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleVGG16(NB_CLASSES)\n",
    "model.loss_fn = nn.CrossEntropyLoss()\n",
    "model.optim = optim.Adam(model.parameters(), lr=LR)\n",
    "model.metrics_dict = {\n",
    "    'precision': precision_metrics,\n",
    "    'accuracy': accuracy_metrics\n",
    "}\n",
    "\n",
    "# load weights\n",
    "model = load_weight(model, WEIGHT1_FILE)\n",
    "history = train_model(model, dl_train, dl_valid, 10, log_per_epochs=1, log_per_steps=200)\n",
    "\n",
    "save_history(model, HISTORY2_FILE)\n",
    "save_weight(model, WEIGHT2_FILE)\n",
    "history"
   ]
  },
  {
   "source": [
    "### metrics plot"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = load_history(HISTORY_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(history, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(history, 'precision')"
   ]
  },
  {
   "source": [
    "### prediction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, _ = next(iter(dl_valid))\n",
    "\n",
    "model = SimpleVGG16(NB_CLASSES)\n",
    "model = load_weight(model, WEIGHT_FILE, net_only=True)\n",
    "\n",
    "targets = predict_model(model, features)\n",
    "print(targets.numpy().reshape(-1, NROWS))\n",
    "\n",
    "plot_images(features, mean=IMAGE_MEAN, std=IMAGE_STD, nrows=NROWS)"
   ]
  },
  {
   "source": [
    "### evaluation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = next(iter(dl_valid))\n",
    "\n",
    "model = SimpleVGG16(NB_CLASSES)\n",
    "model.metrics_dict = {\n",
    "    'precision': precision_metrics,\n",
    "    'accuracy': accuracy_metrics\n",
    "}\n",
    "model = load_weight(model, WEIGHT_FILE, net_only=True)\n",
    "\n",
    "metrics = eval_model(model, features, labels)\n",
    "\n",
    "# print(labels.reshape(-1, NROWS))\n",
    "# plot_images(features)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-0.0046, -0.0142, -0.0822],\n",
       "        [ 0.0523, -0.0474,  0.0054],\n",
       "        [-0.0129, -0.0052, -0.0351]])"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "model = models.vgg16()\n",
    "# Model(model).summary(input_shape=(3, 32, 32))\n",
    "model.state_dict()['features.0.weight'][0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-0.5537,  0.1427,  0.5290],\n",
       "        [-0.5831,  0.3566,  0.7657],\n",
       "        [-0.6902, -0.0480,  0.4841]])"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "model1 = models.vgg16(pretrained=True)\n",
    "model1.state_dict()['features.0.weight'][0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = SimpleVGG16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = load_weight(model2, WEIGHT1_FILE, net_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-0.5784,  0.1180,  0.5037],\n",
       "        [-0.6086,  0.3356,  0.7520],\n",
       "        [-0.7151, -0.0606,  0.4800]])"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "model2.state_dict()['vgg16.features.0.weight'][0, 0, :]"
   ]
  }
 ]
}