{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "ba15a1d979e8ac337d80e71852c3e63572e72a2fa439e8c45e7ad782aa6c2900"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Key words\n",
    "- mnist\n",
    "- customerized CNN, Alexnet, DenseNet\n",
    "- load python file in python notebook\n",
    "- hidden layers visualization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### packages and globe settings"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load shared.py\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from shared import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, transforms, utils, models\n",
    "from torch.utils import data\n",
    "from torchkeras import summary, Model\n",
    "from sklearn.metrics import precision_score, accuracy_score\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "\n",
    "MNIST_ROOT = os.path.join('..', 'data')\n",
    "MNIST_PATH = os.path.join(MNIST_ROOT, 'MNIST')\n",
    "\n",
    "HISTORY_FILE = os.path.join(MNIST_PATH, 'c3_mnist_history.csv')\n",
    "WEIGHT_FILE = os.path.join(MNIST_PATH, 'c3_mnist_weight.pth')\n",
    "\n",
    "HISTORY1_FILE = os.path.join(MNIST_PATH, 'c3_mnist_history1.csv')\n",
    "HISTORY2_FILE = os.path.join(MNIST_PATH, 'c3_mnist_history2.csv')\n",
    "\n",
    "WEIGHT1_FILE = os.path.join(MNIST_PATH, 'c3_mnist_weight1.pth')\n",
    "WEIGHT2_FILE = os.path.join(MNIST_PATH, 'c3_mnist_weight2.pth')\n",
    "\n",
    "NB_CLASSES = 10\n",
    "NROWS = 8\n",
    "\n",
    "IMAGE_MEAN = 0.5\n",
    "IMAGE_STD = 0.5\n",
    "IMAGE_CHANNEL = 1\n",
    "IMAGE_WIDTH = 28\n",
    "IMAGE_HEIGHT = 28\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "VAL_BATCH_SIZE = 32\n",
    "LR = 1e-2"
   ]
  },
  {
   "source": [
    "### datasets and dataloader"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets and dataloader\n",
    "data_tf = transforms.Compose([\n",
    "    transforms.ToTensor(),  # 0~255 -> 0~1\n",
    "    transforms.Normalize((IMAGE_MEAN, ), (IMAGE_STD, ))  # 0~1 -> -1~1\n",
    "])\n",
    "\n",
    "ds_train = datasets.MNIST(MNIST_ROOT, train=True, transform=data_tf, download=True)\n",
    "ds_valid = datasets.MNIST(MNIST_ROOT, train=False, transform=data_tf, download=True)\n",
    "\n",
    "dl_train = data.DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "dl_valid = data.DataLoader(ds_valid, batch_size=VAL_BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "source": [
    "### network class"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, nb_classes=10, *args, **kwargs):\n",
    "        super(SimpleCNN, self).__init__(*args, **kwargs)\n",
    "        self.epoch = 0\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(IMAGE_CHANNEL, 32, 3)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.max_pool1 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.flatten1 = nn.Flatten()\n",
    "\n",
    "        self.fc1 = nn.Linear(5408, 32)\n",
    "        self.fc2 = nn.Linear(32, nb_classes)\n",
    "\n",
    "        self.logsoftmax1 = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        input = self.conv1(input)\n",
    "        input = self.relu1(input)\n",
    "        input = self.max_pool1(input)\n",
    "\n",
    "        input = self.flatten1(input)\n",
    "\n",
    "        input = self.fc1(input)\n",
    "        input = self.fc2(input)\n",
    "\n",
    "        input = self.logsoftmax1(input)\n",
    "\n",
    "        return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model(SimpleCNN(NB_CLASSES)).summary(input_shape=(IMAGE_CHANNEL, IMAGE_WIDTH, IMAGE_HEIGHT))"
   ]
  },
  {
   "source": [
    "### model training and save history and weights"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# training settings (loss, optim & metrics)\n",
    "model = SimpleCNN(NB_CLASSES)\n",
    "model.loss_fn = nn.CrossEntropyLoss()\n",
    "model.optim = optim.Adam(model.parameters(), lr=LR)\n",
    "model.metrics_dict = {\n",
    "    'precision': precision_metrics,\n",
    "    'accuracy': accuracy_metrics\n",
    "}\n",
    "\n",
    "# model training\n",
    "history = train_model(model, dl_train, dl_valid, epochs=20, log_per_epochs=1, log_per_steps=200)\n",
    "\n",
    "# save training history\n",
    "save_history(model, HISTORY1_FILE)\n",
    "\n",
    "# save weights\n",
    "save_weight(model, WEIGHT1_FILE)"
   ]
  },
  {
   "source": [
    "### ouputs of hidden layers"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward hook\n",
    "def hook_fn(module, input, output):\n",
    "    print(module)\n",
    "    output_shape = output.data.shape\n",
    "    plot_images(output.data.reshape(-1, 1, output_shape[-2], output_shape[-1]), mean=IMAGE_MEAN, std=IMAGE_STD, nrows=output_shape[0], figsize=(10, 10))\n",
    "\n",
    "\n",
    "model = SimpleCNN(NB_CLASSES)\n",
    "model.metrics_dict = {\n",
    "    'precision': precision_metrics,\n",
    "    'accuracy': accuracy_metrics\n",
    "}\n",
    "\n",
    "model = load_weight(model, WEIGHT1_FILE, net_only=True)\n",
    "\n",
    "# hooks = {}\n",
    "# for name, module in model.named_children():\n",
    "#     hooks[name] = module.register_forward_hook(hook_fn)\n",
    "\n",
    "features, labels = next(iter(dl_valid))\n",
    "# plot origin\n",
    "plot_images(features, mean=IMAGE_MEAN, std=IMAGE_STD, nrows=VAL_BATCH_SIZE, figsize=(10, 2))\n",
    "\n",
    "# plot outputs of layers conv1, relu1, max_pool1\n",
    "model.conv1.register_forward_hook(hook_fn)\n",
    "model.relu1.register_forward_hook(hook_fn)\n",
    "model.max_pool1.register_forward_hook(hook_fn)\n",
    "\n",
    "eval_model(model, features, labels)"
   ]
  },
  {
   "source": [
    "### visualization of Alexnet hidden layers"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, transforms, utils, models\n",
    "from torch.utils import data\n",
    "from torchkeras import summary, Model\n",
    "from sklearn.metrics import precision_score, accuracy_score\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "Model(models.alexnet()).summary(input_shape=(3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_CHANNEL = 3\n",
    "IMAGE_MEAN = (0.485, 0.456, 0.406)\n",
    "IMAGE_STD = (0.229, 0.224, 0.225)\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    print(module)\n",
    "    output_shape = output.data.shape\n",
    "    print(output_shape)\n",
    "    plot_images(output.data.reshape(-1, 1, output_shape[-2], output_shape[-1]), mean=IMAGE_MEAN, std=IMAGE_STD, nrows=output_shape[-1], figsize=(16, 16))\n",
    "\n",
    "# ds, dl\n",
    "DATASET_ROOT = os.path.join('..', 'data')\n",
    "DATASET_PATH = os.path.join(DATASET_ROOT, 'custom')\n",
    "\n",
    "data_tf = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=IMAGE_MEAN, std=IMAGE_STD),\n",
    "])\n",
    "\n",
    "ds = datasets.ImageFolder(DATASET_PATH, transform=data_tf)\n",
    "dl = data.DataLoader(ds)\n",
    "\n",
    "features, _ = next(iter(dl))\n",
    "# plot_images(features, IMAGE_MEAN, IMAGE_STD)\n",
    "\n",
    "model = models.alexnet(pretrained=True)\n",
    "model.features[2].register_forward_hook(hook_fn)\n",
    "model.features[5].register_forward_hook(hook_fn)\n",
    "model.features[7].register_forward_hook(hook_fn)\n",
    "model.features[9].register_forward_hook(hook_fn)\n",
    "model.features[12].register_forward_hook(hook_fn)\n",
    "\n",
    "# features.shape\n",
    "predict_model(model, features)"
   ]
  },
  {
   "source": [
    "### DenseNet with cifar10"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, transforms, utils, models\n",
    "from torch.utils import data\n",
    "from torchkeras import summary, Model\n",
    "from sklearn.metrics import precision_score, accuracy_score\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "\n",
    "IMAGE_CHANNEL = 3\n",
    "IMAGE_MEAN = (0.5, 0.5, 0.5)\n",
    "IMAGE_STD = (0.5, 0.5, 0.5)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "VAL_BATCH_SIZE = 64\n",
    "\n",
    "LR=1e-3\n",
    "\n",
    "# ds, dl\n",
    "CIFAR10_ROOT = os.path.join('..', 'data')\n",
    "CIFAR10_PATH = os.path.join(CIFAR10_ROOT, 'cifar-10-batches-py')\n",
    "\n",
    "data_tf = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomGrayscale(),\n",
    "    transforms.ToTensor(),  # 0~255 -> 0~1\n",
    "    transforms.Normalize(IMAGE_MEAN, IMAGE_STD) # 0~1 -> -1~1\n",
    "])\n",
    "\n",
    "ds_train = datasets.CIFAR10(CIFAR10_ROOT, train=True, transform=data_tf, download=True)\n",
    "ds_valid = datasets.CIFAR10(CIFAR10_ROOT, train=False, transform=data_tf, download=True)\n",
    "\n",
    "dl_train = data.DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "dl_valid = data.DataLoader(ds_valid, batch_size=VAL_BATCH_SIZE, shuffle=True)\n",
    "\n",
    "class SimpleDenseNet121(nn.Module):\n",
    "    def __init__(self, classes=10, *args, **kwargs):\n",
    "        super(SimpleDenseNet121, self).__init__(*args, **kwargs)\n",
    "        self.epoch = 0\n",
    "        \n",
    "        self.densenet121 = models.densenet121(pretrained=True)\n",
    "        self._freeze()\n",
    "        \n",
    "        self.fc1 = nn.Linear(1000, classes)\n",
    "\n",
    "    def _freeze(self):\n",
    "        for param in self.densenet121.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, input):\n",
    "        input = self.densenet121(input)\n",
    "        input = self.fc1(input)\n",
    "        return input\n",
    "\n",
    "model = SimpleDenseNet121(classes=10)\n",
    "model.loss_fn = nn.CrossEntropyLoss()\n",
    "model.optim = optim.Adam(model.parameters(), lr=LR)\n",
    "model.metrics_dict = {\n",
    "    'precision': precision_metrics,\n",
    "    'accuracy': accuracy_metrics\n",
    "}\n",
    "\n",
    "history = train_model(model, dl_train, dl_valid, 10)\n",
    "\n",
    "features, _ = next(iter(dl_valid))\n",
    "# plot_images(features, IMAGE_MEAN, IMAGE_STD)\n",
    "predict_model(model, features)"
   ]
  }
 ]
}