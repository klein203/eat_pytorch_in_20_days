{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('py38_cv': conda)",
   "metadata": {
    "interpreter": {
     "hash": "ba15a1d979e8ac337d80e71852c3e63572e72a2fa439e8c45e7ad782aa6c2900"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "#打印时间\n",
    "def printbar():\n",
    "    nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(\"\\n\"+\"==========\"*8 + \"%s\"%nowtime)\n",
    "\n",
    "#mac系统上pytorch和matplotlib在jupyter中同时跑需要更改环境变量\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt \n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "#样本数量\n",
    "n = 400\n",
    "\n",
    "# 生成测试用数据集\n",
    "X = 10 * torch.rand((n, 2)) - 5.0\n",
    "w0 = torch.tensor([[2.0], [-3.0]])\n",
    "b0 = torch.tensor([[10.0]])\n",
    "Y = X@w0 + b0 + torch.normal(0.0, 2.0, size=(n, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "ax1 = plt.subplot(121)\n",
    "ax1.scatter(X[:, 0].numpy(), Y[:, 0].numpy(), c=\"b\", label=\"samples\")\n",
    "ax1.legend()\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"y\", rotation=0)\n",
    "\n",
    "ax2 = plt.subplot(122)\n",
    "ax2.scatter(X[:, 1].numpy(), Y[:, 0].numpy(), c=\"g\", label=\"samples\")\n",
    "ax2.legend()\n",
    "plt.xlabel(\"x2\")\n",
    "plt.ylabel(\"y\", rotation=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建数据管道迭代器\n",
    "def data_iter(features, labels, batch_size=8):\n",
    "    num_examples = len(features)\n",
    "    indices = list(range(num_examples))\n",
    "    np.random.shuffle(indices)  #样本的读取顺序是随机的\n",
    "    for i in range(0, num_examples, batch_size):\n",
    "        indexs = torch.LongTensor(indices[i: min(i + batch_size, num_examples)])\n",
    "        yield features.index_select(0, indexs), labels.index_select(0, indexs)\n",
    "\n",
    "# 测试数据管道效果\n",
    "batch_size = 8\n",
    "(features, labels) = next(data_iter(X, Y, batch_size))\n",
    "print(features)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression: \n",
    "    def __init__(self):\n",
    "        self.w = torch.randn_like(w0, requires_grad=True)\n",
    "        self.b = torch.zeros_like(b0, requires_grad=True)\n",
    "\n",
    "    def forward(self, x): \n",
    "        return x@self.w + self.b\n",
    "\n",
    "    def loss_func(self, y_pred, y_true):  \n",
    "        return torch.mean((y_pred - y_true) ** 2 / 2)\n",
    "\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, features, labels):\n",
    "    lr = 0.001\n",
    "    predictions = model.forward(features)\n",
    "    loss = model.loss_func(predictions, labels)\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    # 使用torch.no_grad()避免梯度记录，也可以通过操作 model.w.data 实现避免梯度记录 \n",
    "    with torch.no_grad():\n",
    "        # 梯度下降法更新参数\n",
    "        model.w -= lr * model.w.grad\n",
    "        model.b -= lr * model.b.grad\n",
    "        \n",
    "        model.w.grad.zero_()\n",
    "        model.b.grad.zero_()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "\n",
    "(features, labels) = next(data_iter(X, Y, batch_size))\n",
    "loss = train_step(model, features, labels)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, epochs):\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        for features, labels in data_iter(X, Y, 10):\n",
    "            loss = train_step(model, features, labels)\n",
    "\n",
    "        if epoch % 200 == 0:\n",
    "            printbar()\n",
    "            print(\"epoch =\", epoch, \"loss =\", loss.item())\n",
    "            print(\"model.w =\", model.w.data)\n",
    "            print(\"model.b =\", model.b.data)\n",
    "\n",
    "train_model(model, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "ax1 = plt.subplot(121)\n",
    "ax1.scatter(X[:, 0].numpy(), Y[:, 0].numpy(), c=\"b\", label=\"samples\")\n",
    "ax1.plot(X[:, 0].numpy(), (model.w[0].data * X[:, 0] + model.b[0].data).numpy(), \"-r\", linewidth=5.0, label=\"model\")\n",
    "ax1.legend()\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"y\",rotation=0)\n",
    "\n",
    "ax2 = plt.subplot(122)\n",
    "ax2.scatter(X[:, 1].numpy(), Y[:, 0].numpy(), c=\"g\", label=\"samples\")\n",
    "ax2.plot(X[:, 1].numpy(), (model.w[1].data * X[:, 1] + model.b[0].data).numpy(), \"-r\", linewidth=5.0, label=\"model\")\n",
    "ax2.legend()\n",
    "plt.xlabel(\"x2\")\n",
    "plt.ylabel(\"y\", rotation=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNN\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "#正负样本数量\n",
    "n_positive, n_negative = 1000, 1000\n",
    "\n",
    "#生成正样本, 小圆环分布\n",
    "r_p = torch.normal(5.0, 1.0, size=[n_positive, 1])  # random r\n",
    "theta_p = 2 * np.pi * torch.rand([n_positive, 1])   # random theta\n",
    "Xp = torch.cat([r_p * torch.cos(theta_p), r_p * torch.sin(theta_p)], axis=1)\n",
    "Yp = torch.ones_like(r_p)\n",
    "\n",
    "#生成负样本, 大圆环分布\n",
    "r_n = torch.normal(8.0, 1.0, size=[n_negative, 1]) \n",
    "theta_n = 2 * np.pi * torch.rand([n_negative, 1])\n",
    "Xn = torch.cat([r_n * torch.cos(theta_n), r_n * torch.sin(theta_n)], axis=1)\n",
    "Yn = torch.zeros_like(r_n)\n",
    "\n",
    "#汇总样本\n",
    "X = torch.cat([Xp, Xn], axis=0)\n",
    "Y = torch.cat([Yp, Yn], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "axe = plt.subplot(111)\n",
    "axe.scatter(Xp[:, 0].numpy(), Xp[:, 1].numpy(), c='r', label='positive')\n",
    "axe.scatter(Xn[:, 0].numpy(), Xn[:, 1].numpy(), c='g', label='negative')\n",
    "axe.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建数据管道迭代器\n",
    "def data_iter(features, labels, batch_size=8):\n",
    "    num_examples = len(features)\n",
    "    indices = list(range(num_examples))\n",
    "    np.random.shuffle(indices)  #样本的读取顺序是随机的\n",
    "    for i in range(0, num_examples, batch_size):\n",
    "        indexs = torch.LongTensor(indices[i: min(i + batch_size, num_examples)])\n",
    "        yield features.index_select(0, indexs), labels.index_select(0, indexs)\n",
    "        \n",
    "# 测试数据管道效果   \n",
    "batch_size = 8\n",
    "(features, labels) = next(data_iter(X, Y, batch_size))\n",
    "print(features)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNNModel, self).__init__()\n",
    "        self.w1 = nn.Parameter(torch.randn(2, 4))\n",
    "        self.b1 = nn.Parameter(torch.zeros(1, 4))\n",
    "        self.w2 = nn.Parameter(torch.randn(4, 8))\n",
    "        self.b2 = nn.Parameter(torch.zeros(1, 8))\n",
    "        self.w3 = nn.Parameter(torch.randn(8, 1))\n",
    "        self.b3 = nn.Parameter(torch.zeros(1, 1))\n",
    "\n",
    "    # 正向传播\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(x@self.w1 + self.b1)\n",
    "        x = torch.relu(x@self.w2 + self.b2)\n",
    "        y = torch.sigmoid(x@self.w3 + self.b3)\n",
    "        return y\n",
    "\n",
    "    # 损失函数(二元交叉熵), BCE Loss\n",
    "    def loss_func(self, y_pred, y_true):  \n",
    "        eps = 1e-7\n",
    "        y_pred = torch.clamp(y_pred, eps, 1.0 - eps)\n",
    "        bce = - y_true * torch.log(y_pred) - (1 - y_true) * torch.log(1 - y_pred)\n",
    "        return torch.mean(bce)\n",
    "\n",
    "    # 评估指标(准确率)\n",
    "    def metric_func(self, y_pred, y_true):\n",
    "        y_pred = torch.where(y_pred > 0.5, torch.ones_like(y_pred, dtype=torch.float32), torch.zeros_like(y_pred,dtype=torch.float32))\n",
    "        acc = torch.mean(1 - torch.abs(y_true - y_pred))\n",
    "        return acc\n",
    "\n",
    "model = DNNModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "(features, labels) = next(data_iter(X, Y, batch_size))\n",
    "\n",
    "predictions = model(features)\n",
    "\n",
    "loss = model.loss_func(labels, predictions)\n",
    "metric = model.metric_func(labels, predictions)\n",
    "\n",
    "print(\"init loss:\", loss.item())\n",
    "print(\"init metric:\", metric.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, features, labels):\n",
    "    lr = 0.01\n",
    "\n",
    "    # 正向传播求损失\n",
    "    predictions = model.forward(features)\n",
    "    loss = model.loss_func(predictions, labels)\n",
    "    metric = model.metric_func(predictions, labels)\n",
    "\n",
    "    # 反向传播求梯度\n",
    "    loss.backward()\n",
    "    \n",
    "    # 梯度下降法更新参数\n",
    "    for param in model.parameters():\n",
    "        #注意是对param.data进行重新赋值,避免此处操作引起梯度记录\n",
    "        param.data = (param.data - lr * param.grad.data) \n",
    "\n",
    "    # 梯度清零\n",
    "    model.zero_grad()\n",
    "\n",
    "    return loss.item(), metric.item()\n",
    "\n",
    "def train_model(model, epochs):\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        loss_list, metric_list = [], []\n",
    "        for features, labels in data_iter(X, Y, 20):\n",
    "            lossi, metrici = train_step(model, features, labels)\n",
    "            loss_list.append(lossi)\n",
    "            metric_list.append(metrici)\n",
    "        \n",
    "        loss = np.mean(loss_list)\n",
    "        metric = np.mean(metric_list)\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            printbar()\n",
    "            print(\"epoch =\", epoch, \" loss =\", loss, \" metric =\", metric)\n",
    "\n",
    "train_model(model, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 结果可视化\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(12, 5))\n",
    "\n",
    "ax1.scatter(Xp[:, 0], Xp[:, 1], c=\"r\", label=\"positive\")\n",
    "ax1.scatter(Xn[:, 0], Xn[:, 1], c=\"g\", label=\"negative\")\n",
    "ax1.legend()\n",
    "ax1.set_title(\"y_true\")\n",
    "\n",
    "Xp_pred = X[torch.squeeze(model.forward(X) >= 0.5)]\n",
    "Xn_pred = X[torch.squeeze(model.forward(X) < 0.5)]\n",
    "\n",
    "ax2.scatter(Xp_pred[:, 0], Xp_pred[:, 1], c=\"r\", label=\"positive\")\n",
    "ax2.scatter(Xn_pred[:, 0], Xn_pred[:, 1], c=\"g\", label=\"negative\")\n",
    "ax2.legend()\n",
    "ax2.set_title(\"y_pred\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ]
}